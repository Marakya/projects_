{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Competition\n",
        "\n",
        "https://www.kaggle.com/competitions/lmsys-chatbot-arena"
      ],
      "metadata": {
        "id": "sW24bo40TPEO"
      },
      "id": "sW24bo40TPEO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "Large language models (LLMs) are rapidly entering our lives, but ensuring their responses resonate with users is critical for successful interaction. This competition presents a unique opportunity to tackle this challenge with real-world data and help us bridge the gap between LLM capability and human preference.\n",
        "\n",
        "We utilized a large dataset collected from Chatbot Arena, where users chat with two anonymous LLMs and choose the answer they prefer. Your task in this competition is to predict which response a user will prefer in these head-to-head battles.\n",
        "\n",
        "This challenge aligns with the concept of \"reward models\" or \"preference models\" in reinforcement learning from human feedback (RLHF). Previous research has identified limitations in directly prompting an existing LLM for preference predictions. These limitations often stem from biases such as favoring responses presented first (position bias), being overly verbose (verbosity bias), or exhibiting self-promotion (self-enhancement bias).\n",
        "\n",
        "We encourage you to explore various machine-learning techniques to build a model that can effectively predict user preferences. Your work will be instrumental in developing LLMs that can tailor responses to individual user preferences, ultimately leading to more user-friendly and widely accepted AI-powered conversation systems."
      ],
      "metadata": {
        "id": "alwUPapVTY6W"
      },
      "id": "alwUPapVTY6W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39b18f5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:27:31.347865Z",
          "iopub.status.busy": "2024-07-19T06:27:31.347541Z",
          "iopub.status.idle": "2024-07-19T06:27:36.486342Z",
          "shell.execute_reply": "2024-07-19T06:27:36.485564Z"
        },
        "papermill": {
          "duration": 5.151627,
          "end_time": "2024-07-19T06:27:36.488560",
          "exception": false,
          "start_time": "2024-07-19T06:27:31.336933",
          "status": "completed"
        },
        "tags": [],
        "id": "e39b18f5"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "P7NhD5gxRPda"
      },
      "id": "P7NhD5gxRPda"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51557f03",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:27:36.509574Z",
          "iopub.status.busy": "2024-07-19T06:27:36.508992Z",
          "iopub.status.idle": "2024-07-19T06:27:36.514083Z",
          "shell.execute_reply": "2024-07-19T06:27:36.513250Z"
        },
        "papermill": {
          "duration": 0.017509,
          "end_time": "2024-07-19T06:27:36.515965",
          "exception": false,
          "start_time": "2024-07-19T06:27:36.498456",
          "status": "completed"
        },
        "tags": [],
        "id": "51557f03"
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "    root = \"/kaggle/input/lmsys-chatbot-arena/\"\n",
        "    train_path = os.path.join(root, \"train.csv\")\n",
        "    test_path = os.path.join(root, \"test.csv\")\n",
        "    sample_submission_path = os.path.join(root, \"sample_submission.csv\")\n",
        "    seed = 42\n",
        "    n_splits = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba9d38b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:27:36.535755Z",
          "iopub.status.busy": "2024-07-19T06:27:36.535484Z",
          "iopub.status.idle": "2024-07-19T06:27:39.745669Z",
          "shell.execute_reply": "2024-07-19T06:27:39.744510Z"
        },
        "papermill": {
          "duration": 3.222609,
          "end_time": "2024-07-19T06:27:39.747921",
          "exception": false,
          "start_time": "2024-07-19T06:27:36.525312",
          "status": "completed"
        },
        "tags": [],
        "id": "fba9d38b",
        "outputId": "75831e42-6ed8-48cf-856b-99da211c975a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape: (10000, 9)\n",
            "test shape: (3, 4)\n",
            "------------------------------------------------------------------------------------------\n",
            "train missing values: 0\n",
            "test missing values: 0\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>Is it morally right to try to have a certain p...</td>\n",
              "      <td>The question of whether it is morally right to...</td>\n",
              "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>What is the difference between marriage licens...</td>\n",
              "      <td>A marriage license is a legal document that al...</td>\n",
              "      <td>A marriage license and a marriage certificate ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>explain function calling. how would you call a...</td>\n",
              "      <td>Function calling is the process of invoking or...</td>\n",
              "      <td>Function calling is the process of invoking a ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>How can I create a test set for a very rare ca...</td>\n",
              "      <td>Creating a test set for a very rare category c...</td>\n",
              "      <td>When building a classifier for a very rare cat...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
              "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
              "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  Is it morally right to try to have a certain p...   \n",
              "1  What is the difference between marriage licens...   \n",
              "2  explain function calling. how would you call a...   \n",
              "3  How can I create a test set for a very rare ca...   \n",
              "4  What is the best way to travel from Tel-Aviv t...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  The question of whether it is morally right to...   \n",
              "1  A marriage license is a legal document that al...   \n",
              "2  Function calling is the process of invoking or...   \n",
              "3  Creating a test set for a very rare category c...   \n",
              "4  The best way to travel from Tel Aviv to Jerusa...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  As an AI, I don't have personal beliefs or opi...               1   \n",
              "1  A marriage license and a marriage certificate ...               0   \n",
              "2  Function calling is the process of invoking a ...               0   \n",
              "3  When building a classifier for a very rare cat...               1   \n",
              "4  The best way to travel from Tel-Aviv to Jerusa...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \n",
              "0               0           0  \n",
              "1               1           0  \n",
              "2               0           1  \n",
              "3               0           0  \n",
              "4               1           0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(config.train_path)\n",
        "test = pd.read_csv(config.test_path)\n",
        "sample_submission = pd.read_csv(config.sample_submission_path)\n",
        "\n",
        "if test.shape[0] < 10:\n",
        "    train = train.iloc[:10000]\n",
        "\n",
        "def process(input_str):\n",
        "    stripped_str = input_str.strip('[]')\n",
        "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
        "    return  ' '.join(sentences)\n",
        "\n",
        "train[\"prompt\"] = train[\"prompt\"].apply(process)\n",
        "train[\"response_a\"] = train[\"response_a\"].apply(process)\n",
        "train[\"response_b\"] = train[\"response_b\"].apply(process)\n",
        "\n",
        "test[\"prompt\"] = test[\"prompt\"].apply(process)\n",
        "test[\"response_a\"] = test[\"response_a\"].apply(process)\n",
        "test[\"response_b\"] = test[\"response_b\"].apply(process)\n",
        "\n",
        "print(f\"train shape: {train.shape}\")\n",
        "print(f\"test shape: {test.shape}\")\n",
        "print(\"-\"*90)\n",
        "print(f\"train missing values: {train.isnull().sum().sum()}\")\n",
        "print(f\"test missing values: {test.isnull().sum().sum()}\")\n",
        "print(\"-\"*90)\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b4cce85",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:27:39.771275Z",
          "iopub.status.busy": "2024-07-19T06:27:39.770877Z",
          "iopub.status.idle": "2024-07-19T06:27:39.776607Z",
          "shell.execute_reply": "2024-07-19T06:27:39.775729Z"
        },
        "papermill": {
          "duration": 0.020127,
          "end_time": "2024-07-19T06:27:39.778439",
          "exception": false,
          "start_time": "2024-07-19T06:27:39.758312",
          "status": "completed"
        },
        "tags": [],
        "id": "3b4cce85"
      },
      "outputs": [],
      "source": [
        "train_prompt = train[\"prompt\"].to_numpy()\n",
        "train_response_a = train[\"response_a\"].to_numpy()\n",
        "train_response_b = train[\"response_b\"].to_numpy()\n",
        "\n",
        "test_prompt = test[\"prompt\"].to_numpy()\n",
        "test_response_a = test[\"response_a\"].to_numpy()\n",
        "test_response_b = test[\"response_b\"].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Feature-engineering the text data"
      ],
      "metadata": {
        "id": "ox3wY6XJRXR3"
      },
      "id": "ox3wY6XJRXR3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text cooding"
      ],
      "metadata": {
        "id": "5L_gfQK8RgQw"
      },
      "id": "5L_gfQK8RgQw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cb1f0f0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:27:39.828409Z",
          "iopub.status.busy": "2024-07-19T06:27:39.828099Z",
          "iopub.status.idle": "2024-07-19T06:27:52.536279Z",
          "shell.execute_reply": "2024-07-19T06:27:52.535558Z"
        },
        "papermill": {
          "duration": 12.721573,
          "end_time": "2024-07-19T06:27:52.538636",
          "exception": false,
          "start_time": "2024-07-19T06:27:39.817063",
          "status": "completed"
        },
        "tags": [],
        "id": "6cb1f0f0"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def embeddings(df):\n",
        "    # Объединяем все текстовые данные в один список\n",
        "    text_data = df['prompt'].tolist() + df['response_a'].tolist() + df['response_b'].tolist()\n",
        "\n",
        "    # Токенизация текста\n",
        "    tokenized_data = [word_tokenize(text.lower()) for text in text_data]\n",
        "\n",
        "    # Тренировка модели Word2Vec\n",
        "    model = Word2Vec(sentences=tokenized_data, vector_size=500, window=5, min_count=1, workers=4)\n",
        "\n",
        "    # Функция для получения вектора текста путем усреднения векторов слов\n",
        "    def get_text_vector(text, model):\n",
        "        words = word_tokenize(text.lower())\n",
        "        word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "        if len(word_vectors) == 0:\n",
        "            return np.zeros(model.vector_size)\n",
        "        return np.mean(word_vectors, axis=0)\n",
        "\n",
        "    # Применяем функцию для каждого текста в датафрейме\n",
        "    df['prompt'] = df['prompt'].apply(lambda x: get_text_vector(x, model))\n",
        "    df['response_a'] = df['response_a'].apply(lambda x: get_text_vector(x, model))\n",
        "    df['response_b'] = df['response_b'].apply(lambda x: get_text_vector(x, model))\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ea5d3a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:27:52.560291Z",
          "iopub.status.busy": "2024-07-19T06:27:52.559702Z",
          "iopub.status.idle": "2024-07-19T06:31:16.025401Z",
          "shell.execute_reply": "2024-07-19T06:31:16.024432Z"
        },
        "papermill": {
          "duration": 203.490116,
          "end_time": "2024-07-19T06:31:16.038964",
          "exception": false,
          "start_time": "2024-07-19T06:27:52.548848",
          "status": "completed"
        },
        "tags": [],
        "id": "35ea5d3a",
        "outputId": "fb16e6eb-a5c5-43c7-dfec-cb48587e8f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[0.14825033, 0.79692966, -0.17288265, -0.00606...</td>\n",
              "      <td>[0.21146363, 0.7052502, -0.23350675, -0.086343...</td>\n",
              "      <td>[0.17299703, 0.9479261, -0.31605896, -0.073043...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[-0.07025688, 0.9806348, -0.5844676, -0.174198...</td>\n",
              "      <td>[0.010892835, 0.9547029, -0.17581093, -0.13037...</td>\n",
              "      <td>[0.06697098, 0.8201421, -0.10287952, -0.131749...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[-0.39479163, 1.1118137, -0.6037361, -0.319885...</td>\n",
              "      <td>[0.05221387, 0.90780586, -0.17406768, -0.25018...</td>\n",
              "      <td>[-0.07777796, 0.84549266, -0.17828469, -0.2079...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[0.15107687, 0.8572051, -0.30020607, -0.016592...</td>\n",
              "      <td>[0.072249986, 0.9642767, -0.10863755, -0.15165...</td>\n",
              "      <td>[0.027496329, 1.023703, -0.14078672, -0.086771...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[-0.24248976, 0.8245399, -0.5598793, -0.248583...</td>\n",
              "      <td>[0.07269159, 0.9384141, -0.07560756, -0.053866...</td>\n",
              "      <td>[0.1793062, 0.8711123, -0.1420633, -0.08027805...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [0.14825033, 0.79692966, -0.17288265, -0.00606...   \n",
              "1  [-0.07025688, 0.9806348, -0.5844676, -0.174198...   \n",
              "2  [-0.39479163, 1.1118137, -0.6037361, -0.319885...   \n",
              "3  [0.15107687, 0.8572051, -0.30020607, -0.016592...   \n",
              "4  [-0.24248976, 0.8245399, -0.5598793, -0.248583...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [0.21146363, 0.7052502, -0.23350675, -0.086343...   \n",
              "1  [0.010892835, 0.9547029, -0.17581093, -0.13037...   \n",
              "2  [0.05221387, 0.90780586, -0.17406768, -0.25018...   \n",
              "3  [0.072249986, 0.9642767, -0.10863755, -0.15165...   \n",
              "4  [0.07269159, 0.9384141, -0.07560756, -0.053866...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [0.17299703, 0.9479261, -0.31605896, -0.073043...               1   \n",
              "1  [0.06697098, 0.8201421, -0.10287952, -0.131749...               0   \n",
              "2  [-0.07777796, 0.84549266, -0.17828469, -0.2079...               0   \n",
              "3  [0.027496329, 1.023703, -0.14078672, -0.086771...               1   \n",
              "4  [0.1793062, 0.8711123, -0.1420633, -0.08027805...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \n",
              "0               0           0  \n",
              "1               1           0  \n",
              "2               0           1  \n",
              "3               0           0  \n",
              "4               1           0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = embeddings(train)\n",
        "test = embeddings(test)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine Similarity\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "TaMYNhUwRr1p"
      },
      "id": "TaMYNhUwRr1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac86cf9b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:31:16.060492Z",
          "iopub.status.busy": "2024-07-19T06:31:16.060177Z",
          "iopub.status.idle": "2024-07-19T06:31:16.070152Z",
          "shell.execute_reply": "2024-07-19T06:31:16.069317Z"
        },
        "papermill": {
          "duration": 0.023041,
          "end_time": "2024-07-19T06:31:16.072141",
          "exception": false,
          "start_time": "2024-07-19T06:31:16.049100",
          "status": "completed"
        },
        "tags": [],
        "id": "ac86cf9b"
      },
      "outputs": [],
      "source": [
        "def prep(data):\n",
        "    def cosine_sim(text1, text2):\n",
        "        response_a_vector = text1.apply(lambda x: np.array((x)))\n",
        "        response_b_vector = text2.apply(lambda x: np.array((x)))\n",
        "        cosine_similarities = [cosine_similarity([vec_a], [vec_b])[0][0] for vec_a, vec_b in zip(response_a_vector, response_b_vector)]\n",
        "#         text1=np.array(text1)\n",
        "#         text2=np.array(text2)\n",
        "#         cos_sim = cosine_similarity(text1, text2)\n",
        "        return cosine_similarities\n",
        "\n",
        "\n",
        "    data[\"respa_respb_cosine_sim\"] = cosine_sim(data[\"response_a\"], data[\"response_b\"])\n",
        "    data[\"respa_prompt_cosine_sim\"] = cosine_sim(data[\"response_a\"], data[\"prompt\"])\n",
        "    data[\"respb_prompt_cosine_sim\"] = cosine_sim(data[\"response_b\"], data[\"prompt\"])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53daaa4e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:31:16.093222Z",
          "iopub.status.busy": "2024-07-19T06:31:16.092981Z",
          "iopub.status.idle": "2024-07-19T06:31:40.527584Z",
          "shell.execute_reply": "2024-07-19T06:31:40.526579Z"
        },
        "papermill": {
          "duration": 24.44806,
          "end_time": "2024-07-19T06:31:40.530163",
          "exception": false,
          "start_time": "2024-07-19T06:31:16.082103",
          "status": "completed"
        },
        "tags": [],
        "id": "53daaa4e",
        "outputId": "abd8b306-87f1-4e7f-cc9d-a410568cd097"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>respa_respb_cosine_sim</th>\n",
              "      <th>respa_respb_jaccard_sim</th>\n",
              "      <th>respa_prompt_cosine_sim</th>\n",
              "      <th>respa_prompt_jaccard_sim</th>\n",
              "      <th>respb_prompt_cosine_sim</th>\n",
              "      <th>respb_prompt_jaccard_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[0.14825033, 0.79692966, -0.17288265, -0.00606...</td>\n",
              "      <td>[0.21146363, 0.7052502, -0.23350675, -0.086343...</td>\n",
              "      <td>[0.17299703, 0.9479261, -0.31605896, -0.073043...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.973350</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.922567</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.949712</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[-0.07025688, 0.9806348, -0.5844676, -0.174198...</td>\n",
              "      <td>[0.010892835, 0.9547029, -0.17581093, -0.13037...</td>\n",
              "      <td>[0.06697098, 0.8201421, -0.10287952, -0.131749...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.990317</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.918969</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.920804</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[-0.39479163, 1.1118137, -0.6037361, -0.319885...</td>\n",
              "      <td>[0.05221387, 0.90780586, -0.17406768, -0.25018...</td>\n",
              "      <td>[-0.07777796, 0.84549266, -0.17828469, -0.2079...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.926621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.773783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.804028</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[0.15107687, 0.8572051, -0.30020607, -0.016592...</td>\n",
              "      <td>[0.072249986, 0.9642767, -0.10863755, -0.15165...</td>\n",
              "      <td>[0.027496329, 1.023703, -0.14078672, -0.086771...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.974948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.913226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.907252</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[-0.24248976, 0.8245399, -0.5598793, -0.248583...</td>\n",
              "      <td>[0.07269159, 0.9384141, -0.07560756, -0.053866...</td>\n",
              "      <td>[0.1793062, 0.8711123, -0.1420633, -0.08027805...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.976064</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.795458</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.777366</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [0.14825033, 0.79692966, -0.17288265, -0.00606...   \n",
              "1  [-0.07025688, 0.9806348, -0.5844676, -0.174198...   \n",
              "2  [-0.39479163, 1.1118137, -0.6037361, -0.319885...   \n",
              "3  [0.15107687, 0.8572051, -0.30020607, -0.016592...   \n",
              "4  [-0.24248976, 0.8245399, -0.5598793, -0.248583...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [0.21146363, 0.7052502, -0.23350675, -0.086343...   \n",
              "1  [0.010892835, 0.9547029, -0.17581093, -0.13037...   \n",
              "2  [0.05221387, 0.90780586, -0.17406768, -0.25018...   \n",
              "3  [0.072249986, 0.9642767, -0.10863755, -0.15165...   \n",
              "4  [0.07269159, 0.9384141, -0.07560756, -0.053866...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [0.17299703, 0.9479261, -0.31605896, -0.073043...               1   \n",
              "1  [0.06697098, 0.8201421, -0.10287952, -0.131749...               0   \n",
              "2  [-0.07777796, 0.84549266, -0.17828469, -0.2079...               0   \n",
              "3  [0.027496329, 1.023703, -0.14078672, -0.086771...               1   \n",
              "4  [0.1793062, 0.8711123, -0.1420633, -0.08027805...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  respa_respb_cosine_sim  \\\n",
              "0               0           0                0.973350   \n",
              "1               1           0                0.990317   \n",
              "2               0           1                0.926621   \n",
              "3               0           0                0.974948   \n",
              "4               1           0                0.976064   \n",
              "\n",
              "   respa_respb_jaccard_sim  respa_prompt_cosine_sim  respa_prompt_jaccard_sim  \\\n",
              "0                      0.0                 0.922567                       0.0   \n",
              "1                      0.0                 0.918969                       0.0   \n",
              "2                      0.0                 0.773783                       0.0   \n",
              "3                      0.0                 0.913226                       0.0   \n",
              "4                      0.0                 0.795458                       0.0   \n",
              "\n",
              "   respb_prompt_cosine_sim  respb_prompt_jaccard_sim  \n",
              "0                 0.949712                       0.0  \n",
              "1                 0.920804                       0.0  \n",
              "2                 0.804028                       0.0  \n",
              "3                 0.907252                       0.0  \n",
              "4                 0.777366                       0.0  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = prep(train)\n",
        "test = prep(test)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jaccard Similarity\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "Generate N-grams¶\n",
        "\n",
        "Description: N-grams are contiguous sequences of 'n' items from a given text. This method helps in analyzing the text at different levels of granularity (unigrams, bigrams, trigrams, etc.).\n",
        "\n",
        "\n",
        "Count N-gram Overlaps\n",
        "\n",
        "Description: This method calculates how many n-grams are common between two texts, helping to measure their similarity."
      ],
      "metadata": {
        "id": "EcuUQxg9R-8V"
      },
      "id": "EcuUQxg9R-8V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df8a8a7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:31:40.553591Z",
          "iopub.status.busy": "2024-07-19T06:31:40.553276Z",
          "iopub.status.idle": "2024-07-19T06:31:40.573576Z",
          "shell.execute_reply": "2024-07-19T06:31:40.572769Z"
        },
        "papermill": {
          "duration": 0.033727,
          "end_time": "2024-07-19T06:31:40.575539",
          "exception": false,
          "start_time": "2024-07-19T06:31:40.541812",
          "status": "completed"
        },
        "tags": [],
        "id": "2df8a8a7"
      },
      "outputs": [],
      "source": [
        "def prep_extra(data,data0):\n",
        "\n",
        "    def jaccard_sim(text1, text2):\n",
        "        set1 = set(text1)\n",
        "        set2 = set(text2)\n",
        "        intersection = set1.intersection(set2)\n",
        "        union = set1.union(set2)\n",
        "        return len(intersection) / len(union)\n",
        "\n",
        "    def tokenize(text):\n",
        "        return nltk.word_tokenize(text.lower())\n",
        "\n",
        "    def generate_ngrams(text, n: int):\n",
        "        tokens = tokenize(text)\n",
        "        return list(ngrams(tokens, n))\n",
        "\n",
        "    def count_ngram_overlaps(text1, text2, n: int) -> int:\n",
        "        try:\n",
        "            ngrams1 = generate_ngrams(text1, n)\n",
        "            ngrams2 = generate_ngrams(text2, n)\n",
        "            counter1 = Counter(ngrams1)\n",
        "            counter2 = Counter(ngrams2)\n",
        "            overlap = counter1 & counter2\n",
        "            overlap_count = sum(overlap.values())\n",
        "            return overlap_count\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "\n",
        "    data[\"respa_respb_jaccard_sim\"] = data0.apply(lambda x: jaccard_sim(x[\"response_a\"], x[\"response_b\"]), axis=1)\n",
        "    data[\"respa_prompt_jaccard_sim\"] = data0.apply(lambda x: jaccard_sim(x[\"response_a\"], x[\"prompt\"]), axis=1)\n",
        "    data[\"respb_prompt_jaccard_sim\"] = data0.apply(lambda x: jaccard_sim(x[\"response_b\"], x[\"prompt\"]), axis=1)\n",
        "\n",
        "\n",
        "    data[\"respa_len\"] = data0[\"response_a\"].apply(lambda x: len(tokenize(x)))\n",
        "    data[\"respb_len\"] = data0[\"response_b\"].apply(lambda x: len(tokenize(x)))\n",
        "    data[\"prompt_len\"] = data0[\"prompt\"].apply(lambda x: len(tokenize(x)))\n",
        "\n",
        "    data[\"respa_prompt_len_ratio\"] = data[\"respa_len\"] / data[\"prompt_len\"]\n",
        "    data[\"respb_prompt_len_ratio\"] = data[\"respb_len\"] / data[\"prompt_len\"]\n",
        "    data[\"respa_respb_len_ratio\"] = data[\"respa_len\"] / data[\"respb_len\"]\n",
        "\n",
        "    data[\"respa_respb_len_diff\"] = data[\"respa_len\"] - data[\"respb_len\"]\n",
        "    data[\"respa_prompt_len_diff\"] = data[\"respa_len\"] - data[\"prompt_len\"]\n",
        "    data[\"respb_prompt_len_diff\"] = data[\"respb_len\"] - data[\"prompt_len\"]\n",
        "\n",
        "    data[\"respa_respb_overlap_unigram\"] = data0.apply(lambda x: count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 1), axis=1)\n",
        "    data[\"respa_respb_overlap_bigram\"] = data0.apply(lambda x: count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 2), axis=1)\n",
        "    data[\"respa_respb_overlap_trigram\"] = data0.apply(lambda x: count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 3), axis=1)\n",
        "\n",
        "    data[\"respa_prompt_overlap_unigram\"] = data0.apply(lambda x: count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 1), axis=1)\n",
        "    data[\"respa_prompt_overlap_bigram\"] = data0.apply(lambda x: count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 2), axis=1)\n",
        "    data[\"respa_prompt_overlap_trigram\"] = data0.apply(lambda x: count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 3), axis=1)\n",
        "\n",
        "    data[\"respb_prompt_overlap_unigram\"] = data0.apply(lambda x: count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 1), axis=1)\n",
        "    data[\"respb_prompt_overlap_bigram\"] = data0.apply(lambda x: count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 2), axis=1)\n",
        "    data[\"respb_prompt_overlap_trigram\"] = data0.apply(lambda x: count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 3), axis=1)\n",
        "\n",
        "\n",
        "    data[\"respa_prompt_overlap_unigram_ratio\"] = data[\"respa_prompt_overlap_unigram\"] / data[\"prompt_len\"]\n",
        "    data[\"respa_prompt_overlap_bigram_ratio\"] = data[\"respa_prompt_overlap_bigram\"] / data[\"prompt_len\"]\n",
        "    data[\"respa_prompt_overlap_trigram_ratio\"] = data[\"respa_prompt_overlap_trigram\"] / data[\"prompt_len\"]\n",
        "\n",
        "    data[\"respb_prompt_overlap_unigram_ratio\"] = data[\"respb_prompt_overlap_unigram\"] / data[\"prompt_len\"]\n",
        "    data[\"respb_prompt_overlap_bigram_ratio\"] = data[\"respb_prompt_overlap_bigram\"] / data[\"prompt_len\"]\n",
        "    data[\"respb_prompt_overlap_trigram_ratio\"] = data[\"respb_prompt_overlap_trigram\"] / data[\"prompt_len\"]\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19cd897d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:31:40.597812Z",
          "iopub.status.busy": "2024-07-19T06:31:40.597566Z",
          "iopub.status.idle": "2024-07-19T06:31:42.324720Z",
          "shell.execute_reply": "2024-07-19T06:31:42.323906Z"
        },
        "papermill": {
          "duration": 1.741294,
          "end_time": "2024-07-19T06:31:42.327346",
          "exception": false,
          "start_time": "2024-07-19T06:31:40.586052",
          "status": "completed"
        },
        "tags": [],
        "id": "19cd897d"
      },
      "outputs": [],
      "source": [
        "train_0 = pd.read_csv(config.train_path)\n",
        "test_0 = pd.read_csv(config.test_path)\n",
        "sample_submission = pd.read_csv(config.sample_submission_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "270aec5b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T06:31:42.351628Z",
          "iopub.status.busy": "2024-07-19T06:31:42.351302Z",
          "iopub.status.idle": "2024-07-19T07:20:40.841043Z",
          "shell.execute_reply": "2024-07-19T07:20:40.840123Z"
        },
        "papermill": {
          "duration": 2938.514682,
          "end_time": "2024-07-19T07:20:40.854177",
          "exception": false,
          "start_time": "2024-07-19T06:31:42.339495",
          "status": "completed"
        },
        "tags": [],
        "id": "270aec5b",
        "outputId": "d81e64fd-5c3a-47f7-e1f1-79a44e6f4794"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>respa_respb_cosine_sim</th>\n",
              "      <th>...</th>\n",
              "      <th>respa_prompt_overlap_trigram</th>\n",
              "      <th>respb_prompt_overlap_unigram</th>\n",
              "      <th>respb_prompt_overlap_bigram</th>\n",
              "      <th>respb_prompt_overlap_trigram</th>\n",
              "      <th>respa_prompt_overlap_unigram_ratio</th>\n",
              "      <th>respa_prompt_overlap_bigram_ratio</th>\n",
              "      <th>respa_prompt_overlap_trigram_ratio</th>\n",
              "      <th>respb_prompt_overlap_unigram_ratio</th>\n",
              "      <th>respb_prompt_overlap_bigram_ratio</th>\n",
              "      <th>respb_prompt_overlap_trigram_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[0.14825033, 0.79692966, -0.17288265, -0.00606...</td>\n",
              "      <td>[0.21146363, 0.7052502, -0.23350675, -0.086343...</td>\n",
              "      <td>[0.17299703, 0.9479261, -0.31605896, -0.073043...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.973350</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[-0.07025688, 0.9806348, -0.5844676, -0.174198...</td>\n",
              "      <td>[0.010892835, 0.9547029, -0.17581093, -0.13037...</td>\n",
              "      <td>[0.06697098, 0.8201421, -0.10287952, -0.131749...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.990317</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>36</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.326531</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.306122</td>\n",
              "      <td>0.102041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[-0.39479163, 1.1118137, -0.6037361, -0.319885...</td>\n",
              "      <td>[0.05221387, 0.90780586, -0.17406768, -0.25018...</td>\n",
              "      <td>[-0.07777796, 0.84549266, -0.17828469, -0.2079...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.926621</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[0.15107687, 0.8572051, -0.30020607, -0.016592...</td>\n",
              "      <td>[0.072249986, 0.9642767, -0.10863755, -0.15165...</td>\n",
              "      <td>[0.027496329, 1.023703, -0.14078672, -0.086771...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.974948</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[-0.24248976, 0.8245399, -0.5598793, -0.248583...</td>\n",
              "      <td>[0.07269159, 0.9384141, -0.07560756, -0.053866...</td>\n",
              "      <td>[0.1793062, 0.8711123, -0.1420633, -0.08027805...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.976064</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.318182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 39 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [0.14825033, 0.79692966, -0.17288265, -0.00606...   \n",
              "1  [-0.07025688, 0.9806348, -0.5844676, -0.174198...   \n",
              "2  [-0.39479163, 1.1118137, -0.6037361, -0.319885...   \n",
              "3  [0.15107687, 0.8572051, -0.30020607, -0.016592...   \n",
              "4  [-0.24248976, 0.8245399, -0.5598793, -0.248583...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [0.21146363, 0.7052502, -0.23350675, -0.086343...   \n",
              "1  [0.010892835, 0.9547029, -0.17581093, -0.13037...   \n",
              "2  [0.05221387, 0.90780586, -0.17406768, -0.25018...   \n",
              "3  [0.072249986, 0.9642767, -0.10863755, -0.15165...   \n",
              "4  [0.07269159, 0.9384141, -0.07560756, -0.053866...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [0.17299703, 0.9479261, -0.31605896, -0.073043...               1   \n",
              "1  [0.06697098, 0.8201421, -0.10287952, -0.131749...               0   \n",
              "2  [-0.07777796, 0.84549266, -0.17828469, -0.2079...               0   \n",
              "3  [0.027496329, 1.023703, -0.14078672, -0.086771...               1   \n",
              "4  [0.1793062, 0.8711123, -0.1420633, -0.08027805...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  respa_respb_cosine_sim  ...  \\\n",
              "0               0           0                0.973350  ...   \n",
              "1               1           0                0.990317  ...   \n",
              "2               0           1                0.926621  ...   \n",
              "3               0           0                0.974948  ...   \n",
              "4               1           0                0.976064  ...   \n",
              "\n",
              "   respa_prompt_overlap_trigram  respb_prompt_overlap_unigram  \\\n",
              "0                            10                            25   \n",
              "1                             6                            36   \n",
              "2                             1                            11   \n",
              "3                             9                            18   \n",
              "4                             4                            17   \n",
              "\n",
              "   respb_prompt_overlap_bigram  respb_prompt_overlap_trigram  \\\n",
              "0                            7                             2   \n",
              "1                           15                             5   \n",
              "2                            5                             1   \n",
              "3                           12                             8   \n",
              "4                           11                             7   \n",
              "\n",
              "   respa_prompt_overlap_unigram_ratio  respa_prompt_overlap_bigram_ratio  \\\n",
              "0                            0.825000                           0.425000   \n",
              "1                            0.734694                           0.326531   \n",
              "2                            0.800000                           0.333333   \n",
              "3                            0.750000                           0.500000   \n",
              "4                            0.727273                           0.409091   \n",
              "\n",
              "   respa_prompt_overlap_trigram_ratio  respb_prompt_overlap_unigram_ratio  \\\n",
              "0                            0.250000                            0.625000   \n",
              "1                            0.122449                            0.734694   \n",
              "2                            0.066667                            0.733333   \n",
              "3                            0.375000                            0.750000   \n",
              "4                            0.181818                            0.772727   \n",
              "\n",
              "   respb_prompt_overlap_bigram_ratio  respb_prompt_overlap_trigram_ratio  \n",
              "0                           0.175000                            0.050000  \n",
              "1                           0.306122                            0.102041  \n",
              "2                           0.333333                            0.066667  \n",
              "3                           0.500000                            0.333333  \n",
              "4                           0.500000                            0.318182  \n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = prep_extra(train, train_0)\n",
        "test = prep_extra(test, test_0)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unique words"
      ],
      "metadata": {
        "id": "5QZWOBVtSv-Z"
      },
      "id": "5QZWOBVtSv-Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff45e37e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:22:57.793592Z",
          "iopub.status.busy": "2024-07-19T07:22:57.792857Z",
          "iopub.status.idle": "2024-07-19T07:22:57.796739Z",
          "shell.execute_reply": "2024-07-19T07:22:57.795903Z"
        },
        "papermill": {
          "duration": 0.017512,
          "end_time": "2024-07-19T07:22:57.798649",
          "exception": false,
          "start_time": "2024-07-19T07:22:57.781137",
          "status": "completed"
        },
        "tags": [],
        "id": "ff45e37e"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d52daa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:22:57.822045Z",
          "iopub.status.busy": "2024-07-19T07:22:57.821614Z",
          "iopub.status.idle": "2024-07-19T07:22:57.826522Z",
          "shell.execute_reply": "2024-07-19T07:22:57.825690Z"
        },
        "papermill": {
          "duration": 0.018875,
          "end_time": "2024-07-19T07:22:57.828606",
          "exception": false,
          "start_time": "2024-07-19T07:22:57.809731",
          "status": "completed"
        },
        "tags": [],
        "id": "f9d52daa"
      },
      "outputs": [],
      "source": [
        "def unic_words_num(df, df_0):\n",
        "    df['unique_words_response_a'] = df_0['response_a'].apply(lambda x: len(set(word_tokenize(x))))\n",
        "    df['unique_words_response_b'] = df_0['response_b'].apply(lambda x: len(set(word_tokenize(x))))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4695a3df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:22:57.852049Z",
          "iopub.status.busy": "2024-07-19T07:22:57.851620Z",
          "iopub.status.idle": "2024-07-19T07:28:41.291569Z",
          "shell.execute_reply": "2024-07-19T07:28:41.290627Z"
        },
        "papermill": {
          "duration": 343.466084,
          "end_time": "2024-07-19T07:28:41.305779",
          "exception": false,
          "start_time": "2024-07-19T07:22:57.839695",
          "status": "completed"
        },
        "tags": [],
        "id": "4695a3df",
        "outputId": "320bf54e-1a53-4f61-db32-433284392d64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>...</th>\n",
              "      <th>respb_prompt_overlap_bigram</th>\n",
              "      <th>respb_prompt_overlap_trigram</th>\n",
              "      <th>respa_prompt_overlap_unigram_ratio</th>\n",
              "      <th>respa_prompt_overlap_bigram_ratio</th>\n",
              "      <th>respa_prompt_overlap_trigram_ratio</th>\n",
              "      <th>respb_prompt_overlap_unigram_ratio</th>\n",
              "      <th>respb_prompt_overlap_bigram_ratio</th>\n",
              "      <th>respb_prompt_overlap_trigram_ratio</th>\n",
              "      <th>unique_words_response_a</th>\n",
              "      <th>unique_words_response_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[ 1.48250327e-01  7.96929657e-01 -1.72882646e-...</td>\n",
              "      <td>[ 2.11463630e-01  7.05250204e-01 -2.33506754e-...</td>\n",
              "      <td>[ 0.17299703  0.9479261  -0.31605896 -0.073043...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>378</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[-0.07025688  0.9806348  -0.5844676  -0.174198...</td>\n",
              "      <td>[ 1.08928354e-02  9.54702914e-01 -1.75810933e-...</td>\n",
              "      <td>[ 6.69709817e-02  8.20142090e-01 -1.02879517e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.326531</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.306122</td>\n",
              "      <td>0.102041</td>\n",
              "      <td>148</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[-0.39479163  1.1118137  -0.6037361  -0.319885...</td>\n",
              "      <td>[ 5.22138700e-02  9.07805860e-01 -1.74067676e-...</td>\n",
              "      <td>[-7.77779594e-02  8.45492661e-01 -1.78284690e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>97</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[ 1.51076868e-01  8.57205093e-01 -3.00206065e-...</td>\n",
              "      <td>[ 7.22499862e-02  9.64276671e-01 -1.08637549e-...</td>\n",
              "      <td>[ 0.02749633  1.023703   -0.14078672 -0.086771...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>169</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[-2.42489755e-01  8.24539900e-01 -5.59879303e-...</td>\n",
              "      <td>[ 7.26915896e-02  9.38414097e-01 -7.56075606e-...</td>\n",
              "      <td>[ 1.79306194e-01  8.71112287e-01 -1.42063305e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>125</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0      id             model_a              model_b  \\\n",
              "0           0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1           1   53567           koala-13b           gpt-4-0613   \n",
              "2           2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3           3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4           4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [ 1.48250327e-01  7.96929657e-01 -1.72882646e-...   \n",
              "1  [-0.07025688  0.9806348  -0.5844676  -0.174198...   \n",
              "2  [-0.39479163  1.1118137  -0.6037361  -0.319885...   \n",
              "3  [ 1.51076868e-01  8.57205093e-01 -3.00206065e-...   \n",
              "4  [-2.42489755e-01  8.24539900e-01 -5.59879303e-...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [ 2.11463630e-01  7.05250204e-01 -2.33506754e-...   \n",
              "1  [ 1.08928354e-02  9.54702914e-01 -1.75810933e-...   \n",
              "2  [ 5.22138700e-02  9.07805860e-01 -1.74067676e-...   \n",
              "3  [ 7.22499862e-02  9.64276671e-01 -1.08637549e-...   \n",
              "4  [ 7.26915896e-02  9.38414097e-01 -7.56075606e-...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [ 0.17299703  0.9479261  -0.31605896 -0.073043...               1   \n",
              "1  [ 6.69709817e-02  8.20142090e-01 -1.02879517e-...               0   \n",
              "2  [-7.77779594e-02  8.45492661e-01 -1.78284690e-...               0   \n",
              "3  [ 0.02749633  1.023703   -0.14078672 -0.086771...               1   \n",
              "4  [ 1.79306194e-01  8.71112287e-01 -1.42063305e-...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  ...  respb_prompt_overlap_bigram  \\\n",
              "0               0           0  ...                            7   \n",
              "1               1           0  ...                           15   \n",
              "2               0           1  ...                            5   \n",
              "3               0           0  ...                           12   \n",
              "4               1           0  ...                           11   \n",
              "\n",
              "   respb_prompt_overlap_trigram  respa_prompt_overlap_unigram_ratio  \\\n",
              "0                             2                            0.825000   \n",
              "1                             5                            0.734694   \n",
              "2                             1                            0.800000   \n",
              "3                             8                            0.750000   \n",
              "4                             7                            0.727273   \n",
              "\n",
              "   respa_prompt_overlap_bigram_ratio  respa_prompt_overlap_trigram_ratio  \\\n",
              "0                           0.425000                            0.250000   \n",
              "1                           0.326531                            0.122449   \n",
              "2                           0.333333                            0.066667   \n",
              "3                           0.500000                            0.375000   \n",
              "4                           0.409091                            0.181818   \n",
              "\n",
              "   respb_prompt_overlap_unigram_ratio  respb_prompt_overlap_bigram_ratio  \\\n",
              "0                            0.625000                           0.175000   \n",
              "1                            0.734694                           0.306122   \n",
              "2                            0.733333                           0.333333   \n",
              "3                            0.750000                           0.500000   \n",
              "4                            0.772727                           0.500000   \n",
              "\n",
              "   respb_prompt_overlap_trigram_ratio  unique_words_response_a  \\\n",
              "0                            0.050000                      378   \n",
              "1                            0.102041                      148   \n",
              "2                            0.066667                       97   \n",
              "3                            0.333333                      169   \n",
              "4                            0.318182                      125   \n",
              "\n",
              "   unique_words_response_b  \n",
              "0                      136  \n",
              "1                      252  \n",
              "2                      140  \n",
              "3                      119  \n",
              "4                       82  \n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = unic_words_num(train,train_0)\n",
        "test = unic_words_num(test,test_0)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis of text"
      ],
      "metadata": {
        "id": "oIZKM6u2Syh_"
      },
      "id": "oIZKM6u2Syh_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c96212",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:28:41.330568Z",
          "iopub.status.busy": "2024-07-19T07:28:41.330064Z",
          "iopub.status.idle": "2024-07-19T07:28:41.376178Z",
          "shell.execute_reply": "2024-07-19T07:28:41.375384Z"
        },
        "papermill": {
          "duration": 0.060579,
          "end_time": "2024-07-19T07:28:41.378118",
          "exception": false,
          "start_time": "2024-07-19T07:28:41.317539",
          "status": "completed"
        },
        "tags": [],
        "id": "22c96212"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "def sentment(df, df_0):\n",
        "    df['sentiment_response_a'] = df_0['response_a'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "    df['sentiment_response_b'] = df_0['response_b'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e69e6a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:28:41.402918Z",
          "iopub.status.busy": "2024-07-19T07:28:41.402644Z",
          "iopub.status.idle": "2024-07-19T07:32:14.438982Z",
          "shell.execute_reply": "2024-07-19T07:32:14.438075Z"
        },
        "papermill": {
          "duration": 213.064012,
          "end_time": "2024-07-19T07:32:14.454156",
          "exception": false,
          "start_time": "2024-07-19T07:28:41.390144",
          "status": "completed"
        },
        "tags": [],
        "id": "22e69e6a",
        "outputId": "3cbece7a-c787-44c2-914f-d861765b89a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>...</th>\n",
              "      <th>respa_prompt_overlap_unigram_ratio</th>\n",
              "      <th>respa_prompt_overlap_bigram_ratio</th>\n",
              "      <th>respa_prompt_overlap_trigram_ratio</th>\n",
              "      <th>respb_prompt_overlap_unigram_ratio</th>\n",
              "      <th>respb_prompt_overlap_bigram_ratio</th>\n",
              "      <th>respb_prompt_overlap_trigram_ratio</th>\n",
              "      <th>unique_words_response_a</th>\n",
              "      <th>unique_words_response_b</th>\n",
              "      <th>sentiment_response_a</th>\n",
              "      <th>sentiment_response_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[ 1.48250327e-01  7.96929657e-01 -1.72882646e-...</td>\n",
              "      <td>[ 2.11463630e-01  7.05250204e-01 -2.33506754e-...</td>\n",
              "      <td>[ 0.17299703  0.9479261  -0.31605896 -0.073043...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>378</td>\n",
              "      <td>136</td>\n",
              "      <td>0.088119</td>\n",
              "      <td>0.130147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[-0.07025688  0.9806348  -0.5844676  -0.174198...</td>\n",
              "      <td>[ 1.08928354e-02  9.54702914e-01 -1.75810933e-...</td>\n",
              "      <td>[ 6.69709817e-02  8.20142090e-01 -1.02879517e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.326531</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.306122</td>\n",
              "      <td>0.102041</td>\n",
              "      <td>148</td>\n",
              "      <td>252</td>\n",
              "      <td>0.054014</td>\n",
              "      <td>0.148230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[-0.39479163  1.1118137  -0.6037361  -0.319885...</td>\n",
              "      <td>[ 5.22138700e-02  9.07805860e-01 -1.74067676e-...</td>\n",
              "      <td>[-7.77779594e-02  8.45492661e-01 -1.78284690e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>97</td>\n",
              "      <td>140</td>\n",
              "      <td>0.276190</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[ 1.51076868e-01  8.57205093e-01 -3.00206065e-...</td>\n",
              "      <td>[ 7.22499862e-02  9.64276671e-01 -1.08637549e-...</td>\n",
              "      <td>[ 0.02749633  1.023703   -0.14078672 -0.086771...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>169</td>\n",
              "      <td>119</td>\n",
              "      <td>0.160765</td>\n",
              "      <td>0.230551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[-2.42489755e-01  8.24539900e-01 -5.59879303e-...</td>\n",
              "      <td>[ 7.26915896e-02  9.38414097e-01 -7.56075606e-...</td>\n",
              "      <td>[ 1.79306194e-01  8.71112287e-01 -1.42063305e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>125</td>\n",
              "      <td>82</td>\n",
              "      <td>0.203846</td>\n",
              "      <td>0.252778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0      id             model_a              model_b  \\\n",
              "0           0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1           1   53567           koala-13b           gpt-4-0613   \n",
              "2           2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3           3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4           4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [ 1.48250327e-01  7.96929657e-01 -1.72882646e-...   \n",
              "1  [-0.07025688  0.9806348  -0.5844676  -0.174198...   \n",
              "2  [-0.39479163  1.1118137  -0.6037361  -0.319885...   \n",
              "3  [ 1.51076868e-01  8.57205093e-01 -3.00206065e-...   \n",
              "4  [-2.42489755e-01  8.24539900e-01 -5.59879303e-...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [ 2.11463630e-01  7.05250204e-01 -2.33506754e-...   \n",
              "1  [ 1.08928354e-02  9.54702914e-01 -1.75810933e-...   \n",
              "2  [ 5.22138700e-02  9.07805860e-01 -1.74067676e-...   \n",
              "3  [ 7.22499862e-02  9.64276671e-01 -1.08637549e-...   \n",
              "4  [ 7.26915896e-02  9.38414097e-01 -7.56075606e-...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [ 0.17299703  0.9479261  -0.31605896 -0.073043...               1   \n",
              "1  [ 6.69709817e-02  8.20142090e-01 -1.02879517e-...               0   \n",
              "2  [-7.77779594e-02  8.45492661e-01 -1.78284690e-...               0   \n",
              "3  [ 0.02749633  1.023703   -0.14078672 -0.086771...               1   \n",
              "4  [ 1.79306194e-01  8.71112287e-01 -1.42063305e-...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  ...  respa_prompt_overlap_unigram_ratio  \\\n",
              "0               0           0  ...                            0.825000   \n",
              "1               1           0  ...                            0.734694   \n",
              "2               0           1  ...                            0.800000   \n",
              "3               0           0  ...                            0.750000   \n",
              "4               1           0  ...                            0.727273   \n",
              "\n",
              "   respa_prompt_overlap_bigram_ratio  respa_prompt_overlap_trigram_ratio  \\\n",
              "0                           0.425000                            0.250000   \n",
              "1                           0.326531                            0.122449   \n",
              "2                           0.333333                            0.066667   \n",
              "3                           0.500000                            0.375000   \n",
              "4                           0.409091                            0.181818   \n",
              "\n",
              "   respb_prompt_overlap_unigram_ratio  respb_prompt_overlap_bigram_ratio  \\\n",
              "0                            0.625000                           0.175000   \n",
              "1                            0.734694                           0.306122   \n",
              "2                            0.733333                           0.333333   \n",
              "3                            0.750000                           0.500000   \n",
              "4                            0.772727                           0.500000   \n",
              "\n",
              "   respb_prompt_overlap_trigram_ratio  unique_words_response_a  \\\n",
              "0                            0.050000                      378   \n",
              "1                            0.102041                      148   \n",
              "2                            0.066667                       97   \n",
              "3                            0.333333                      169   \n",
              "4                            0.318182                      125   \n",
              "\n",
              "   unique_words_response_b  sentiment_response_a  sentiment_response_b  \n",
              "0                      136              0.088119              0.130147  \n",
              "1                      252              0.054014              0.148230  \n",
              "2                      140              0.276190              0.083333  \n",
              "3                      119              0.160765              0.230551  \n",
              "4                       82              0.203846              0.252778  \n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = sentment(train,train_0)\n",
        "test = sentment(test,test_0)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic Matching (LDA Topic Modeling)"
      ],
      "metadata": {
        "id": "fiGvB_HiTFZl"
      },
      "id": "fiGvB_HiTFZl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6c33d1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:32:14.480421Z",
          "iopub.status.busy": "2024-07-19T07:32:14.480096Z",
          "iopub.status.idle": "2024-07-19T07:32:14.489060Z",
          "shell.execute_reply": "2024-07-19T07:32:14.488309Z"
        },
        "papermill": {
          "duration": 0.023953,
          "end_time": "2024-07-19T07:32:14.490902",
          "exception": false,
          "start_time": "2024-07-19T07:32:14.466949",
          "status": "completed"
        },
        "tags": [],
        "id": "ae6c33d1"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def lda_sem(df,df_0):\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "    prompts_and_responses = df_0['prompt'] + df_0['response_a'] + df_0['response_b']\n",
        "    X = vectorizer.fit_transform(prompts_and_responses)\n",
        "    lda = LatentDirichletAllocation(n_components=10, random_state=0)\n",
        "    lda.fit(X)\n",
        "\n",
        "    def compute_topic_distribution(text):\n",
        "        X_text = vectorizer.transform([text])\n",
        "        return lda.transform(X_text)[0]\n",
        "\n",
        "    df['topic_dist_prompt'] = df_0['prompt'].apply(lambda x: compute_topic_distribution(x))\n",
        "    df['topic_dist_response_a'] = df_0['response_a'].apply(lambda x: compute_topic_distribution(x))\n",
        "    df['topic_dist_response_b'] = df_0['response_b'].apply(lambda x: compute_topic_distribution(x))\n",
        "\n",
        "    def compute_topic_similarity(prompt_dist, response_dist):\n",
        "        return np.dot(prompt_dist, response_dist)\n",
        "\n",
        "    df['topic_similarity_response_a'] = df.apply(lambda x: compute_topic_similarity(x['topic_dist_prompt'], x['topic_dist_response_a']), axis=1)\n",
        "    df['topic_similarity_response_b'] = df.apply(lambda x: compute_topic_similarity(x['topic_dist_prompt'], x['topic_dist_response_b']), axis=1)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6722f4e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:32:14.516564Z",
          "iopub.status.busy": "2024-07-19T07:32:14.516273Z",
          "iopub.status.idle": "2024-07-19T07:46:00.073745Z",
          "shell.execute_reply": "2024-07-19T07:46:00.072776Z"
        },
        "papermill": {
          "duration": 825.586489,
          "end_time": "2024-07-19T07:46:00.089755",
          "exception": false,
          "start_time": "2024-07-19T07:32:14.503266",
          "status": "completed"
        },
        "tags": [],
        "id": "b6722f4e",
        "outputId": "cde7e70c-8f13-4e8f-a54f-1a35417a27b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>...</th>\n",
              "      <th>respb_prompt_overlap_trigram_ratio</th>\n",
              "      <th>unique_words_response_a</th>\n",
              "      <th>unique_words_response_b</th>\n",
              "      <th>sentiment_response_a</th>\n",
              "      <th>sentiment_response_b</th>\n",
              "      <th>topic_dist_prompt</th>\n",
              "      <th>topic_dist_response_a</th>\n",
              "      <th>topic_dist_response_b</th>\n",
              "      <th>topic_similarity_response_a</th>\n",
              "      <th>topic_similarity_response_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[ 1.48250327e-01  7.96929657e-01 -1.72882646e-...</td>\n",
              "      <td>[ 2.11463630e-01  7.05250204e-01 -2.33506754e-...</td>\n",
              "      <td>[ 0.17299703  0.9479261  -0.31605896 -0.073043...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>378</td>\n",
              "      <td>136</td>\n",
              "      <td>0.088119</td>\n",
              "      <td>0.130147</td>\n",
              "      <td>[0.0035714978733118663, 0.0035727873136843376,...</td>\n",
              "      <td>[0.0001512927458127778, 0.0001513316587953256,...</td>\n",
              "      <td>[0.0005128249931057372, 0.0005129812381744884,...</td>\n",
              "      <td>0.233883</td>\n",
              "      <td>0.270951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[-0.07025688  0.9806348  -0.5844676  -0.174198...</td>\n",
              "      <td>[ 1.08928354e-02  9.54702914e-01 -1.75810933e-...</td>\n",
              "      <td>[ 6.69709817e-02  8.20142090e-01 -1.02879517e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102041</td>\n",
              "      <td>148</td>\n",
              "      <td>252</td>\n",
              "      <td>0.054014</td>\n",
              "      <td>0.148230</td>\n",
              "      <td>[0.0028571683318059948, 0.1196307424053573, 0....</td>\n",
              "      <td>[0.00019960265298000235, 0.0001996520964445076...</td>\n",
              "      <td>[0.00018182010195809362, 0.0001818721504973176...</td>\n",
              "      <td>0.211429</td>\n",
              "      <td>0.189571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[-0.39479163  1.1118137  -0.6037361  -0.319885...</td>\n",
              "      <td>[ 5.22138700e-02  9.07805860e-01 -1.74067676e-...</td>\n",
              "      <td>[-7.77779594e-02  8.45492661e-01 -1.78284690e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>97</td>\n",
              "      <td>140</td>\n",
              "      <td>0.276190</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>[0.011111119650613451, 0.011113756375514684, 0...</td>\n",
              "      <td>[0.0007299331721190057, 0.19283552811787508, 0...</td>\n",
              "      <td>[0.00037736094612099885, 0.34884326722868747, ...</td>\n",
              "      <td>0.339641</td>\n",
              "      <td>0.276481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[ 1.51076868e-01  8.57205093e-01 -3.00206065e-...</td>\n",
              "      <td>[ 7.22499862e-02  9.64276671e-01 -1.08637549e-...</td>\n",
              "      <td>[ 0.02749633  1.023703   -0.14078672 -0.086771...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>169</td>\n",
              "      <td>119</td>\n",
              "      <td>0.160765</td>\n",
              "      <td>0.230551</td>\n",
              "      <td>[0.007142902955310745, 0.1781692153249614, 0.0...</td>\n",
              "      <td>[0.0001926795679706063, 0.2900806066283786, 0....</td>\n",
              "      <td>[0.0003773613411540632, 0.44263046156831554, 0...</td>\n",
              "      <td>0.206698</td>\n",
              "      <td>0.165479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[-2.42489755e-01  8.24539900e-01 -5.59879303e-...</td>\n",
              "      <td>[ 7.26915896e-02  9.38414097e-01 -7.56075606e-...</td>\n",
              "      <td>[ 1.79306194e-01  8.71112287e-01 -1.42063305e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>125</td>\n",
              "      <td>82</td>\n",
              "      <td>0.203846</td>\n",
              "      <td>0.252778</td>\n",
              "      <td>[0.006251996931222836, 0.006253349836846019, 0...</td>\n",
              "      <td>[0.0004464660635576031, 0.000446573790425593, ...</td>\n",
              "      <td>[0.0007936915294493722, 0.0007938749223657878,...</td>\n",
              "      <td>0.243447</td>\n",
              "      <td>0.197438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 49 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0      id             model_a              model_b  \\\n",
              "0           0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1           1   53567           koala-13b           gpt-4-0613   \n",
              "2           2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3           3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4           4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [ 1.48250327e-01  7.96929657e-01 -1.72882646e-...   \n",
              "1  [-0.07025688  0.9806348  -0.5844676  -0.174198...   \n",
              "2  [-0.39479163  1.1118137  -0.6037361  -0.319885...   \n",
              "3  [ 1.51076868e-01  8.57205093e-01 -3.00206065e-...   \n",
              "4  [-2.42489755e-01  8.24539900e-01 -5.59879303e-...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [ 2.11463630e-01  7.05250204e-01 -2.33506754e-...   \n",
              "1  [ 1.08928354e-02  9.54702914e-01 -1.75810933e-...   \n",
              "2  [ 5.22138700e-02  9.07805860e-01 -1.74067676e-...   \n",
              "3  [ 7.22499862e-02  9.64276671e-01 -1.08637549e-...   \n",
              "4  [ 7.26915896e-02  9.38414097e-01 -7.56075606e-...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [ 0.17299703  0.9479261  -0.31605896 -0.073043...               1   \n",
              "1  [ 6.69709817e-02  8.20142090e-01 -1.02879517e-...               0   \n",
              "2  [-7.77779594e-02  8.45492661e-01 -1.78284690e-...               0   \n",
              "3  [ 0.02749633  1.023703   -0.14078672 -0.086771...               1   \n",
              "4  [ 1.79306194e-01  8.71112287e-01 -1.42063305e-...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  ...  respb_prompt_overlap_trigram_ratio  \\\n",
              "0               0           0  ...                            0.050000   \n",
              "1               1           0  ...                            0.102041   \n",
              "2               0           1  ...                            0.066667   \n",
              "3               0           0  ...                            0.333333   \n",
              "4               1           0  ...                            0.318182   \n",
              "\n",
              "   unique_words_response_a  unique_words_response_b  sentiment_response_a  \\\n",
              "0                      378                      136              0.088119   \n",
              "1                      148                      252              0.054014   \n",
              "2                       97                      140              0.276190   \n",
              "3                      169                      119              0.160765   \n",
              "4                      125                       82              0.203846   \n",
              "\n",
              "   sentiment_response_b                                  topic_dist_prompt  \\\n",
              "0              0.130147  [0.0035714978733118663, 0.0035727873136843376,...   \n",
              "1              0.148230  [0.0028571683318059948, 0.1196307424053573, 0....   \n",
              "2              0.083333  [0.011111119650613451, 0.011113756375514684, 0...   \n",
              "3              0.230551  [0.007142902955310745, 0.1781692153249614, 0.0...   \n",
              "4              0.252778  [0.006251996931222836, 0.006253349836846019, 0...   \n",
              "\n",
              "                               topic_dist_response_a  \\\n",
              "0  [0.0001512927458127778, 0.0001513316587953256,...   \n",
              "1  [0.00019960265298000235, 0.0001996520964445076...   \n",
              "2  [0.0007299331721190057, 0.19283552811787508, 0...   \n",
              "3  [0.0001926795679706063, 0.2900806066283786, 0....   \n",
              "4  [0.0004464660635576031, 0.000446573790425593, ...   \n",
              "\n",
              "                               topic_dist_response_b  \\\n",
              "0  [0.0005128249931057372, 0.0005129812381744884,...   \n",
              "1  [0.00018182010195809362, 0.0001818721504973176...   \n",
              "2  [0.00037736094612099885, 0.34884326722868747, ...   \n",
              "3  [0.0003773613411540632, 0.44263046156831554, 0...   \n",
              "4  [0.0007936915294493722, 0.0007938749223657878,...   \n",
              "\n",
              "   topic_similarity_response_a  topic_similarity_response_b  \n",
              "0                     0.233883                     0.270951  \n",
              "1                     0.211429                     0.189571  \n",
              "2                     0.339641                     0.276481  \n",
              "3                     0.206698                     0.165479  \n",
              "4                     0.243447                     0.197438  \n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = lda_sem(train,train_0)\n",
        "test = lda_sem(test,test_0)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d25c6f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:46:00.191643Z",
          "iopub.status.busy": "2024-07-19T07:46:00.191337Z",
          "iopub.status.idle": "2024-07-19T07:46:15.123008Z",
          "shell.execute_reply": "2024-07-19T07:46:15.122008Z"
        },
        "papermill": {
          "duration": 14.94847,
          "end_time": "2024-07-19T07:46:15.125262",
          "exception": false,
          "start_time": "2024-07-19T07:46:00.176792",
          "status": "completed"
        },
        "tags": [],
        "id": "e3d25c6f"
      },
      "outputs": [],
      "source": [
        "train.to_csv('train_fin.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "iLxGeyHGTKSf"
      },
      "id": "iLxGeyHGTKSf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e18594d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:46:15.155296Z",
          "iopub.status.busy": "2024-07-19T07:46:15.154990Z",
          "iopub.status.idle": "2024-07-19T07:46:15.189014Z",
          "shell.execute_reply": "2024-07-19T07:46:15.188195Z"
        },
        "papermill": {
          "duration": 0.050289,
          "end_time": "2024-07-19T07:46:15.190848",
          "exception": false,
          "start_time": "2024-07-19T07:46:15.140559",
          "status": "completed"
        },
        "tags": [],
        "id": "2e18594d",
        "outputId": "6cdf75d3-6a99-4329-93e1-79426a21dc02"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>...</th>\n",
              "      <th>unique_words_response_a</th>\n",
              "      <th>unique_words_response_b</th>\n",
              "      <th>sentiment_response_a</th>\n",
              "      <th>sentiment_response_b</th>\n",
              "      <th>topic_dist_prompt</th>\n",
              "      <th>topic_dist_response_a</th>\n",
              "      <th>topic_dist_response_b</th>\n",
              "      <th>topic_similarity_response_a</th>\n",
              "      <th>topic_similarity_response_b</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[ 1.48250327e-01  7.96929657e-01 -1.72882646e-...</td>\n",
              "      <td>[ 2.11463630e-01  7.05250204e-01 -2.33506754e-...</td>\n",
              "      <td>[ 0.17299703  0.9479261  -0.31605896 -0.073043...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>378</td>\n",
              "      <td>136</td>\n",
              "      <td>0.088119</td>\n",
              "      <td>0.130147</td>\n",
              "      <td>[0.0035714978733118663, 0.0035727873136843376,...</td>\n",
              "      <td>[0.0001512927458127778, 0.0001513316587953256,...</td>\n",
              "      <td>[0.0005128249931057372, 0.0005129812381744884,...</td>\n",
              "      <td>0.233883</td>\n",
              "      <td>0.270951</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[-0.07025688  0.9806348  -0.5844676  -0.174198...</td>\n",
              "      <td>[ 1.08928354e-02  9.54702914e-01 -1.75810933e-...</td>\n",
              "      <td>[ 6.69709817e-02  8.20142090e-01 -1.02879517e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>148</td>\n",
              "      <td>252</td>\n",
              "      <td>0.054014</td>\n",
              "      <td>0.148230</td>\n",
              "      <td>[0.0028571683318059948, 0.1196307424053573, 0....</td>\n",
              "      <td>[0.00019960265298000235, 0.0001996520964445076...</td>\n",
              "      <td>[0.00018182010195809362, 0.0001818721504973176...</td>\n",
              "      <td>0.211429</td>\n",
              "      <td>0.189571</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[-0.39479163  1.1118137  -0.6037361  -0.319885...</td>\n",
              "      <td>[ 5.22138700e-02  9.07805860e-01 -1.74067676e-...</td>\n",
              "      <td>[-7.77779594e-02  8.45492661e-01 -1.78284690e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>140</td>\n",
              "      <td>0.276190</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>[0.011111119650613451, 0.011113756375514684, 0...</td>\n",
              "      <td>[0.0007299331721190057, 0.19283552811787508, 0...</td>\n",
              "      <td>[0.00037736094612099885, 0.34884326722868747, ...</td>\n",
              "      <td>0.339641</td>\n",
              "      <td>0.276481</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[ 1.51076868e-01  8.57205093e-01 -3.00206065e-...</td>\n",
              "      <td>[ 7.22499862e-02  9.64276671e-01 -1.08637549e-...</td>\n",
              "      <td>[ 0.02749633  1.023703   -0.14078672 -0.086771...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>169</td>\n",
              "      <td>119</td>\n",
              "      <td>0.160765</td>\n",
              "      <td>0.230551</td>\n",
              "      <td>[0.007142902955310745, 0.1781692153249614, 0.0...</td>\n",
              "      <td>[0.0001926795679706063, 0.2900806066283786, 0....</td>\n",
              "      <td>[0.0003773613411540632, 0.44263046156831554, 0...</td>\n",
              "      <td>0.206698</td>\n",
              "      <td>0.165479</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[-2.42489755e-01  8.24539900e-01 -5.59879303e-...</td>\n",
              "      <td>[ 7.26915896e-02  9.38414097e-01 -7.56075606e-...</td>\n",
              "      <td>[ 1.79306194e-01  8.71112287e-01 -1.42063305e-...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>125</td>\n",
              "      <td>82</td>\n",
              "      <td>0.203846</td>\n",
              "      <td>0.252778</td>\n",
              "      <td>[0.006251996931222836, 0.006253349836846019, 0...</td>\n",
              "      <td>[0.0004464660635576031, 0.000446573790425593, ...</td>\n",
              "      <td>[0.0007936915294493722, 0.0007938749223657878,...</td>\n",
              "      <td>0.243447</td>\n",
              "      <td>0.197438</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0      id             model_a              model_b  \\\n",
              "0           0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1           1   53567           koala-13b           gpt-4-0613   \n",
              "2           2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3           3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4           4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [ 1.48250327e-01  7.96929657e-01 -1.72882646e-...   \n",
              "1  [-0.07025688  0.9806348  -0.5844676  -0.174198...   \n",
              "2  [-0.39479163  1.1118137  -0.6037361  -0.319885...   \n",
              "3  [ 1.51076868e-01  8.57205093e-01 -3.00206065e-...   \n",
              "4  [-2.42489755e-01  8.24539900e-01 -5.59879303e-...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [ 2.11463630e-01  7.05250204e-01 -2.33506754e-...   \n",
              "1  [ 1.08928354e-02  9.54702914e-01 -1.75810933e-...   \n",
              "2  [ 5.22138700e-02  9.07805860e-01 -1.74067676e-...   \n",
              "3  [ 7.22499862e-02  9.64276671e-01 -1.08637549e-...   \n",
              "4  [ 7.26915896e-02  9.38414097e-01 -7.56075606e-...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [ 0.17299703  0.9479261  -0.31605896 -0.073043...               1   \n",
              "1  [ 6.69709817e-02  8.20142090e-01 -1.02879517e-...               0   \n",
              "2  [-7.77779594e-02  8.45492661e-01 -1.78284690e-...               0   \n",
              "3  [ 0.02749633  1.023703   -0.14078672 -0.086771...               1   \n",
              "4  [ 1.79306194e-01  8.71112287e-01 -1.42063305e-...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  ...  unique_words_response_a  \\\n",
              "0               0           0  ...                      378   \n",
              "1               1           0  ...                      148   \n",
              "2               0           1  ...                       97   \n",
              "3               0           0  ...                      169   \n",
              "4               1           0  ...                      125   \n",
              "\n",
              "   unique_words_response_b  sentiment_response_a  sentiment_response_b  \\\n",
              "0                      136              0.088119              0.130147   \n",
              "1                      252              0.054014              0.148230   \n",
              "2                      140              0.276190              0.083333   \n",
              "3                      119              0.160765              0.230551   \n",
              "4                       82              0.203846              0.252778   \n",
              "\n",
              "                                   topic_dist_prompt  \\\n",
              "0  [0.0035714978733118663, 0.0035727873136843376,...   \n",
              "1  [0.0028571683318059948, 0.1196307424053573, 0....   \n",
              "2  [0.011111119650613451, 0.011113756375514684, 0...   \n",
              "3  [0.007142902955310745, 0.1781692153249614, 0.0...   \n",
              "4  [0.006251996931222836, 0.006253349836846019, 0...   \n",
              "\n",
              "                               topic_dist_response_a  \\\n",
              "0  [0.0001512927458127778, 0.0001513316587953256,...   \n",
              "1  [0.00019960265298000235, 0.0001996520964445076...   \n",
              "2  [0.0007299331721190057, 0.19283552811787508, 0...   \n",
              "3  [0.0001926795679706063, 0.2900806066283786, 0....   \n",
              "4  [0.0004464660635576031, 0.000446573790425593, ...   \n",
              "\n",
              "                               topic_dist_response_b  \\\n",
              "0  [0.0005128249931057372, 0.0005129812381744884,...   \n",
              "1  [0.00018182010195809362, 0.0001818721504973176...   \n",
              "2  [0.00037736094612099885, 0.34884326722868747, ...   \n",
              "3  [0.0003773613411540632, 0.44263046156831554, 0...   \n",
              "4  [0.0007936915294493722, 0.0007938749223657878,...   \n",
              "\n",
              "   topic_similarity_response_a  topic_similarity_response_b  target  \n",
              "0                     0.233883                     0.270951       0  \n",
              "1                     0.211429                     0.189571       1  \n",
              "2                     0.339641                     0.276481       2  \n",
              "3                     0.206698                     0.165479       0  \n",
              "4                     0.243447                     0.197438       1  \n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "drop_cols = [\"id\", \"response_a\", \"response_b\", \"prompt\", \"topic_dist_prompt\",\"topic_dist_response_a\",\"topic_dist_response_b\"]\n",
        "# drop_cols = [\"id\"]\n",
        "target_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
        "target = \"target\"\n",
        "\n",
        "train[target] = np.nan\n",
        "for idx, t in enumerate(target_cols):\n",
        "    train.loc[train[t] == 1, target] = idx\n",
        "train[target] = train[target].astype(\"int32\")\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83d52c45",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:46:15.279545Z",
          "iopub.status.busy": "2024-07-19T07:46:15.278900Z",
          "iopub.status.idle": "2024-07-19T07:46:15.291338Z",
          "shell.execute_reply": "2024-07-19T07:46:15.290512Z"
        },
        "papermill": {
          "duration": 0.030713,
          "end_time": "2024-07-19T07:46:15.293423",
          "exception": false,
          "start_time": "2024-07-19T07:46:15.262710",
          "status": "completed"
        },
        "tags": [],
        "id": "83d52c45"
      },
      "outputs": [],
      "source": [
        "X = train.drop(columns=target_cols+drop_cols+[target]+[\"model_a\", \"model_b\"], axis=1)\n",
        "y = train[target]\n",
        "X_test = test.drop(columns=drop_cols, axis=1)\n",
        "\n",
        "X = X.replace([-np.inf, np.inf], np.nan)\n",
        "X_test = X_test.replace([-np.inf, np.inf], np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f93a7f2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:46:15.323877Z",
          "iopub.status.busy": "2024-07-19T07:46:15.323613Z",
          "iopub.status.idle": "2024-07-19T07:46:15.337545Z",
          "shell.execute_reply": "2024-07-19T07:46:15.336845Z"
        },
        "papermill": {
          "duration": 0.031132,
          "end_time": "2024-07-19T07:46:15.339402",
          "exception": false,
          "start_time": "2024-07-19T07:46:15.308270",
          "status": "completed"
        },
        "tags": [],
        "id": "9f93a7f2"
      },
      "outputs": [],
      "source": [
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2df840a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:46:15.369585Z",
          "iopub.status.busy": "2024-07-19T07:46:15.369285Z",
          "iopub.status.idle": "2024-07-19T07:46:44.555424Z",
          "shell.execute_reply": "2024-07-19T07:46:44.554170Z"
        },
        "papermill": {
          "duration": 29.203775,
          "end_time": "2024-07-19T07:46:44.557668",
          "exception": false,
          "start_time": "2024-07-19T07:46:15.353893",
          "status": "completed"
        },
        "tags": [],
        "id": "e2df840a",
        "outputId": "29c9d286-da57-45a4-c2ea-91f94aef2d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model: catboost\n",
            "[   0    1    2 ... 9997 9998 9999]\n",
            "0:\tlearn: 1.0951310\ttest: 1.0951310\ttest1: 1.0947605\tbest: 1.0947605 (0)\ttotal: 64ms\tremaining: 41.6s\n",
            "75:\tlearn: 1.0285322\ttest: 1.0285322\ttest1: 1.0335303\tbest: 1.0335303 (75)\ttotal: 652ms\tremaining: 4.92s\n",
            "150:\tlearn: 1.0126236\ttest: 1.0126236\ttest1: 1.0306083\tbest: 1.0305021 (147)\ttotal: 1.23s\tremaining: 4.07s\n",
            "225:\tlearn: 0.9967792\ttest: 0.9967792\ttest1: 1.0305208\tbest: 1.0300543 (180)\ttotal: 1.8s\tremaining: 3.38s\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.030054337\n",
            "bestIteration = 180\n",
            "\n",
            "Shrink model to first 181 iterations.\n",
            "[   0    1    3 ... 9997 9998 9999]\n",
            "0:\tlearn: 1.0949456\ttest: 1.0949456\ttest1: 1.0953265\tbest: 1.0953265 (0)\ttotal: 9.55ms\tremaining: 6.2s\n",
            "75:\tlearn: 1.0277761\ttest: 1.0277761\ttest1: 1.0443874\tbest: 1.0443874 (75)\ttotal: 594ms\tremaining: 4.49s\n",
            "150:\tlearn: 1.0106914\ttest: 1.0106914\ttest1: 1.0415358\tbest: 1.0415358 (150)\ttotal: 1.16s\tremaining: 3.82s\n",
            "225:\tlearn: 0.9957178\ttest: 0.9957178\ttest1: 1.0419312\tbest: 1.0413324 (161)\ttotal: 1.73s\tremaining: 3.24s\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.041332395\n",
            "bestIteration = 161\n",
            "\n",
            "Shrink model to first 162 iterations.\n",
            "[   0    1    2 ... 9995 9996 9999]\n",
            "0:\tlearn: 1.0947575\ttest: 1.0947575\ttest1: 1.0953298\tbest: 1.0953298 (0)\ttotal: 9.2ms\tremaining: 5.97s\n",
            "75:\tlearn: 1.0265978\ttest: 1.0265978\ttest1: 1.0522979\tbest: 1.0520155 (72)\ttotal: 593ms\tremaining: 4.48s\n",
            "150:\tlearn: 1.0109758\ttest: 1.0109758\ttest1: 1.0517310\tbest: 1.0515331 (135)\ttotal: 1.16s\tremaining: 3.84s\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.051533091\n",
            "bestIteration = 135\n",
            "\n",
            "Shrink model to first 136 iterations.\n",
            "[   0    2    3 ... 9996 9997 9998]\n",
            "0:\tlearn: 1.0950250\ttest: 1.0950250\ttest1: 1.0951896\tbest: 1.0951896 (0)\ttotal: 11ms\tremaining: 7.14s\n",
            "75:\tlearn: 1.0293175\ttest: 1.0293175\ttest1: 1.0372433\tbest: 1.0370734 (74)\ttotal: 606ms\tremaining: 4.57s\n",
            "150:\tlearn: 1.0117754\ttest: 1.0117754\ttest1: 1.0341650\tbest: 1.0341650 (150)\ttotal: 1.18s\tremaining: 3.9s\n",
            "225:\tlearn: 0.9970917\ttest: 0.9970917\ttest1: 1.0342210\tbest: 1.0336288 (218)\ttotal: 1.76s\tremaining: 3.31s\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.03362876\n",
            "bestIteration = 218\n",
            "\n",
            "Shrink model to first 219 iterations.\n",
            "[   0    1    2 ... 9997 9998 9999]\n",
            "0:\tlearn: 1.0945837\ttest: 1.0945837\ttest1: 1.0957114\tbest: 1.0957114 (0)\ttotal: 9.01ms\tremaining: 5.85s\n",
            "75:\tlearn: 1.0251542\ttest: 1.0251542\ttest1: 1.0667367\tbest: 1.0657063 (63)\ttotal: 602ms\tremaining: 4.54s\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.065706253\n",
            "bestIteration = 63\n",
            "\n",
            "Shrink model to first 64 iterations.\n",
            "[   0    1    2 ... 9997 9998 9999]\n",
            "0:\tlearn: 1.0947159\ttest: 1.0947159\ttest1: 1.0951269\tbest: 1.0951269 (0)\ttotal: 8.84ms\tremaining: 5.74s\n",
            "75:\tlearn: 1.0266723\ttest: 1.0266723\ttest1: 1.0455143\tbest: 1.0455143 (75)\ttotal: 597ms\tremaining: 4.51s\n",
            "150:\tlearn: 1.0106569\ttest: 1.0106569\ttest1: 1.0422941\tbest: 1.0422941 (150)\ttotal: 1.17s\tremaining: 3.88s\n",
            "225:\tlearn: 0.9967489\ttest: 0.9967489\ttest1: 1.0404216\tbest: 1.0403363 (222)\ttotal: 1.75s\tremaining: 3.28s\n",
            "300:\tlearn: 0.9807959\ttest: 0.9807959\ttest1: 1.0395051\tbest: 1.0394499 (291)\ttotal: 2.31s\tremaining: 2.68s\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.039449872\n",
            "bestIteration = 291\n",
            "\n",
            "Shrink model to first 292 iterations.\n",
            "[   0    1    2 ... 9997 9998 9999]\n",
            "0:\tlearn: 1.0950102\ttest: 1.0950102\ttest1: 1.0949340\tbest: 1.0949340 (0)\ttotal: 9.32ms\tremaining: 6.05s\n",
            "75:\tlearn: 1.0284967\ttest: 1.0284967\ttest1: 1.0345319\tbest: 1.0344192 (74)\ttotal: 612ms\tremaining: 4.62s\n",
            "150:\tlearn: 1.0124080\ttest: 1.0124080\ttest1: 1.0303612\tbest: 1.0303612 (150)\ttotal: 1.18s\tremaining: 3.9s\n",
            "225:\tlearn: 0.9974597\ttest: 0.9974597\ttest1: 1.0294963\tbest: 1.0292471 (215)\ttotal: 1.8s\tremaining: 3.38s\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.02924714\n",
            "bestIteration = 215\n",
            "\n",
            "Shrink model to first 216 iterations.\n",
            "[   0    1    2 ... 9997 9998 9999]\n",
            "0:\tlearn: 1.0950504\ttest: 1.0950504\ttest1: 1.0949546\tbest: 1.0949546 (0)\ttotal: 10.9ms\tremaining: 7.05s\n",
            "75:\tlearn: 1.0282033\ttest: 1.0282033\ttest1: 1.0405017\tbest: 1.0405017 (75)\ttotal: 619ms\tremaining: 4.67s\n",
            "150:\tlearn: 1.0121128\ttest: 1.0121128\ttest1: 1.0374623\tbest: 1.0374094 (148)\ttotal: 1.2s\tremaining: 3.97s\n",
            "225:\tlearn: 0.9969226\ttest: 0.9969226\ttest1: 1.0356336\tbest: 1.0354526 (216)\ttotal: 1.8s\tremaining: 3.38s\n",
            "300:\tlearn: 0.9813502\ttest: 0.9813502\ttest1: 1.0352167\tbest: 1.0351386 (274)\ttotal: 2.36s\tremaining: 2.74s\n",
            "375:\tlearn: 0.9654574\ttest: 0.9654574\ttest1: 1.0334906\tbest: 1.0333984 (374)\ttotal: 2.93s\tremaining: 2.14s\n",
            "450:\tlearn: 0.9503651\ttest: 0.9503651\ttest1: 1.0333791\tbest: 1.0332011 (436)\ttotal: 3.5s\tremaining: 1.54s\n",
            "525:\tlearn: 0.9356216\ttest: 0.9356216\ttest1: 1.0339690\tbest: 1.0328845 (468)\ttotal: 4.07s\tremaining: 960ms\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.032884539\n",
            "bestIteration = 468\n",
            "\n",
            "Shrink model to first 469 iterations.\n",
            "[   0    1    2 ... 9997 9998 9999]\n",
            "0:\tlearn: 1.0950132\ttest: 1.0950132\ttest1: 1.0947481\tbest: 1.0947481 (0)\ttotal: 9.49ms\tremaining: 6.16s\n",
            "75:\tlearn: 1.0286408\ttest: 1.0286408\ttest1: 1.0413414\tbest: 1.0413414 (75)\ttotal: 608ms\tremaining: 4.59s\n",
            "150:\tlearn: 1.0123211\ttest: 1.0123211\ttest1: 1.0386589\tbest: 1.0382055 (137)\ttotal: 1.19s\tremaining: 3.93s\n",
            "225:\tlearn: 0.9976842\ttest: 0.9976842\ttest1: 1.0382145\tbest: 1.0380737 (215)\ttotal: 1.75s\tremaining: 3.28s\n",
            "300:\tlearn: 0.9809153\ttest: 0.9809153\ttest1: 1.0373716\tbest: 1.0373716 (300)\ttotal: 2.33s\tremaining: 2.7s\n",
            "375:\tlearn: 0.9654138\ttest: 0.9654138\ttest1: 1.0376396\tbest: 1.0369500 (307)\ttotal: 2.89s\tremaining: 2.11s\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.036950015\n",
            "bestIteration = 307\n",
            "\n",
            "Shrink model to first 308 iterations.\n",
            "[   1    2    3 ... 9997 9998 9999]\n",
            "0:\tlearn: 1.0950387\ttest: 1.0950387\ttest1: 1.0957663\tbest: 1.0957663 (0)\ttotal: 11.1ms\tremaining: 7.22s\n",
            "75:\tlearn: 1.0269889\ttest: 1.0269889\ttest1: 1.0534835\tbest: 1.0534835 (75)\ttotal: 599ms\tremaining: 4.53s\n",
            "150:\tlearn: 1.0111023\ttest: 1.0111023\ttest1: 1.0510634\tbest: 1.0508083 (146)\ttotal: 1.21s\tremaining: 3.99s\n",
            "225:\tlearn: 0.9962959\ttest: 0.9962959\ttest1: 1.0482410\tbest: 1.0482410 (225)\ttotal: 1.77s\tremaining: 3.32s\n",
            "300:\tlearn: 0.9804543\ttest: 0.9804543\ttest1: 1.0481138\tbest: 1.0479413 (297)\ttotal: 2.33s\tremaining: 2.7s\n",
            "375:\tlearn: 0.9656508\ttest: 0.9656508\ttest1: 1.0462622\tbest: 1.0462622 (375)\ttotal: 2.89s\tremaining: 2.11s\n",
            "450:\tlearn: 0.9509585\ttest: 0.9509585\ttest1: 1.0460980\tbest: 1.0458104 (423)\ttotal: 3.47s\tremaining: 1.53s\n",
            "Stopped by overfitting detector  (75 iterations wait)\n",
            "\n",
            "bestTest = 1.04581042\n",
            "bestIteration = 423\n",
            "\n",
            "Shrink model to first 424 iterations.\n",
            "Mean CV Log Loss: 1.04066\n",
            "\n",
            "Best Model:\n",
            "Model          catboost\n",
            "CV_Log_Loss     1.04066\n",
            "Name: 0, dtype: object\n",
            "\n",
            "Results DataFrame:\n",
            "      Model  CV_Log_Loss\n",
            "0  catboost      1.04066\n"
          ]
        }
      ],
      "source": [
        "# Define models and their configurations\n",
        "models = {\n",
        "    'catboost': {\n",
        "        'model': cb.CatBoostClassifier(\n",
        "            loss_function='MultiClass',\n",
        "            iterations=650,\n",
        "            learning_rate=0.045,\n",
        "            depth=5,\n",
        "            random_seed=0,\n",
        "#             task_type=\"GPU\",  # Use GPU if available\n",
        "            verbose=75\n",
        "        ),\n",
        "        'params': {}\n",
        "    },\n",
        "      # 'xgboost': {\n",
        "      #         'model': xgb.XGBClassifier(\n",
        "      #             objective='multi:softprob',\n",
        "      #             num_class=3,\n",
        "      #             eval_metric='mlogloss',\n",
        "      #             subsample=0.8,\n",
        "      #             n_estimators=650,\n",
        "      #             learning_rate=0.045,\n",
        "      #             max_depth=5,\n",
        "      #             random_state=0,\n",
        "      #             enable_categorical=True\n",
        "      # #             tree_method='gpu_hist'  # GPU acceleration if available\n",
        "      #         ),\n",
        "      #         'params': {}\n",
        "      #     },\n",
        "}\n",
        "\n",
        "# Select features using SelectKBest\n",
        "selector = SelectKBest(f_classif, k=25)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "X_test_new = selector.transform(X_test)\n",
        "\n",
        "# X_new = X\n",
        "# X_test_new = X_test\n",
        "\n",
        "# Cross-validation setup\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
        "\n",
        "# Dataframe to store results\n",
        "results = []\n",
        "\n",
        "# Iterate over models\n",
        "for model_name, model_data in models.items():\n",
        "    model = model_data['model']\n",
        "    print(f\"Training model: {model_name}\")\n",
        "\n",
        "    test_preds = np.zeros(shape=(X_test_new.shape[0], y.nunique()))\n",
        "    cv_scores = []\n",
        "\n",
        "    for idx, (train_idx, val_idx) in enumerate(cv.split(X_new, y)):\n",
        "        print(train_idx)\n",
        "        X_train, y_train = X_new[train_idx], y[train_idx]\n",
        "        X_val, y_val = X_new[val_idx], y[val_idx]\n",
        "        # X_train, y_train = X_new.iloc[train_idx], y.iloc[train_idx]\n",
        "        # X_val, y_val = X_new.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "        if model_name == 'voting':\n",
        "            model.fit(X_train, y_train)\n",
        "        elif model_name == 'catboost':\n",
        "            model.fit(\n",
        "                X_train,\n",
        "                y_train,\n",
        "                eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "                early_stopping_rounds=75,\n",
        "                verbose=75\n",
        "            )\n",
        "        else:\n",
        "            model.fit(\n",
        "                X_train,\n",
        "                y_train\n",
        "            )\n",
        "\n",
        "        if model_name != 'voting':\n",
        "            val_preds = model.predict_proba(X_val)\n",
        "            val_log_loss = log_loss(y_val, val_preds, eps=\"auto\")\n",
        "            cv_scores.append(val_log_loss)\n",
        "\n",
        "            test_preds += model.predict_proba(X_test_new) / cv.get_n_splits()\n",
        "\n",
        "    if model_name != 'voting':\n",
        "        mean_cv_log_loss = np.mean(cv_scores)\n",
        "        results.append({'Model': model_name, 'CV_Log_Loss': mean_cv_log_loss})\n",
        "        print(f\"Mean CV Log Loss: {mean_cv_log_loss:.5f}\")\n",
        "\n",
        "# Store feature importances if applicable\n",
        "if model_name in ['random_forest', 'gradient_boosting', 'xgboost', 'catboost']:\n",
        "    features = X.columns[selector.get_support()].tolist()\n",
        "    feat_imp_df = pd.DataFrame({\"feature\": features})\n",
        "    feat_imp_df[f\"{model_name}_avg_importance\"] = 0\n",
        "\n",
        "    for idx, (_, val_idx) in enumerate(cv.split(X_new, y)):\n",
        "        X_val, _ = X_new[val_idx], y[val_idx]\n",
        "        feat_imp_df[f\"{model_name}_avg_importance\"] += model.feature_importances_ / cv.get_n_splits()\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df = pd.concat([results_df, feat_imp_df], axis=1)\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Identify the best model\n",
        "best_model = results_df.loc[results_df['CV_Log_Loss'].idxmin()]\n",
        "print(f\"\\nBest Model:\\n{best_model}\")\n",
        "\n",
        "# Display results DataFrame\n",
        "print(\"\\nResults DataFrame:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b788e5c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:46:44.596956Z",
          "iopub.status.busy": "2024-07-19T07:46:44.596686Z",
          "iopub.status.idle": "2024-07-19T07:46:44.611930Z",
          "shell.execute_reply": "2024-07-19T07:46:44.611041Z"
        },
        "papermill": {
          "duration": 0.036878,
          "end_time": "2024-07-19T07:46:44.613870",
          "exception": false,
          "start_time": "2024-07-19T07:46:44.576992",
          "status": "completed"
        },
        "tags": [],
        "id": "8b788e5c"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv(config.sample_submission_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebead7e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:46:44.653136Z",
          "iopub.status.busy": "2024-07-19T07:46:44.652342Z",
          "iopub.status.idle": "2024-07-19T07:46:44.663328Z",
          "shell.execute_reply": "2024-07-19T07:46:44.662489Z"
        },
        "papermill": {
          "duration": 0.0326,
          "end_time": "2024-07-19T07:46:44.665266",
          "exception": false,
          "start_time": "2024-07-19T07:46:44.632666",
          "status": "completed"
        },
        "tags": [],
        "id": "ebead7e2",
        "outputId": "53f23d3a-47a4-4c3a-aeff-978dc8646cda"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>136060</td>\n",
              "      <td>0.243833</td>\n",
              "      <td>0.344306</td>\n",
              "      <td>0.411861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>211333</td>\n",
              "      <td>0.451736</td>\n",
              "      <td>0.212785</td>\n",
              "      <td>0.335479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1233961</td>\n",
              "      <td>0.406488</td>\n",
              "      <td>0.292166</td>\n",
              "      <td>0.301346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  winner_model_a  winner_model_b  winner_tie\n",
              "0   136060        0.243833        0.344306    0.411861\n",
              "1   211333        0.451736        0.212785    0.335479\n",
              "2  1233961        0.406488        0.292166    0.301346"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for idx, t in enumerate(target_cols):\n",
        "    submission[t] = test_preds[:, idx]\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde95874",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T07:46:44.704274Z",
          "iopub.status.busy": "2024-07-19T07:46:44.704005Z",
          "iopub.status.idle": "2024-07-19T07:46:44.709213Z",
          "shell.execute_reply": "2024-07-19T07:46:44.708383Z"
        },
        "papermill": {
          "duration": 0.026956,
          "end_time": "2024-07-19T07:46:44.711150",
          "exception": false,
          "start_time": "2024-07-19T07:46:44.684194",
          "status": "completed"
        },
        "tags": [],
        "id": "bde95874"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4f3574",
      "metadata": {
        "papermill": {
          "duration": 0.018822,
          "end_time": "2024-07-19T07:46:44.748886",
          "exception": false,
          "start_time": "2024-07-19T07:46:44.730064",
          "status": "completed"
        },
        "tags": [],
        "id": "cd4f3574"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faff60bb",
      "metadata": {
        "papermill": {
          "duration": 0.018868,
          "end_time": "2024-07-19T07:46:44.786782",
          "exception": false,
          "start_time": "2024-07-19T07:46:44.767914",
          "status": "completed"
        },
        "tags": [],
        "id": "faff60bb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 8346466,
          "sourceId": 66631,
          "sourceType": "competition"
        },
        {
          "datasetId": 5409331,
          "sourceId": 8982596,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30746,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4791.49108,
      "end_time": "2024-07-19T07:46:45.934740",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-07-19T06:26:54.443660",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}