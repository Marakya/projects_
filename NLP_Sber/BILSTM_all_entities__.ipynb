{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d73c2f",
   "metadata": {
    "id": "92d73c2f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63c1dd6",
   "metadata": {
    "id": "f63c1dd6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fa9afb",
   "metadata": {
    "id": "02fa9afb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff94a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_addons -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbd37ec",
   "metadata": {
    "id": "3fbd37ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "import keras as k\n",
    "# from keras_contrib.layers import CRF\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow_addons.text import CRFModelWrapper\n",
    "# from keras_contrib.layers import CRF\n",
    "# from tensorflow_addons.layers import CRF\n",
    "# from tf_crf_layer.loss import crf_loss\n",
    "# from tf_crf_layer.metrics import crf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd16b0d",
   "metadata": {
    "id": "dbd16b0d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Conv1D, Dense, Dropout, Softmax, MaxPooling1D, Input, Embedding, TimeDistributed\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow_addons.text import CRFModelWrapper\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098796da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.12.0\n",
      "Tensorflow addons version 0.20.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version {tf.__version__}\")\n",
    "print(f\"Tensorflow addons version {tfa.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "C-5evkIgzf_K",
   "metadata": {
    "id": "C-5evkIgzf_K"
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data_entities_100_.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "B9FRc34qz_8J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "B9FRc34qz_8J",
    "outputId": "60b82c55-720d-4074-cf7e-9f5dc9ec6515"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>text_ind</th>\n",
       "      <th>tag_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[субсидия, предоставляться, в, предел, бюджетн...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[10, 123, 2, 481, 83, 574, 3, 366, 83, 138, 1,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[основной, понятие, ,, использовать, в, настоя...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[854, 549, 1, 384, 2, 34, 13, 53, 170, 4, 35, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[доступ, к, функция, сервис, для, участник, от...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[1653, 50, 400, 2198, 37, 27, 11, 339, 1279, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[;, участник, отбор, -, представить, в, уполно...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[8, 27, 11, 7, 428, 2, 326, 100, 170, 4, 35, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[отбор, получатель, субсидия, проводиться, упо...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[11, 36, 10, 661, 326, 100, 562, 334, 170, 4, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12330</th>\n",
       "      <td>[к, категория, получатель, субсидия, в, рамка,...</td>\n",
       "      <td>[O, O, O, O, i-e-org-ul, O, O, O, O, i-e-org-u...</td>\n",
       "      <td>[50, 243, 36, 10, 2, 236, 34, 13, 503, 22, 16,...</td>\n",
       "      <td>[1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 4, 4, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331</th>\n",
       "      <td>[;, 2, ), получатель, субсидия, -, юридический...</td>\n",
       "      <td>[i-e-org-ul, i-e-org-ul, i-e-org-ul, i-e-treb-...</td>\n",
       "      <td>[8, 45, 5, 36, 10, 7, 22, 16, 1, 12, 199, 2, 1...</td>\n",
       "      <td>[3, 3, 3, 9, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12332</th>\n",
       "      <td>[;, (, в, ред, ., постановление, правительство...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[8, 4, 2, 141, 9, 62, 72, 393, 71, 32, 439, 9,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12333</th>\n",
       "      <td>[;, 5, ), представить, в, министерство, (, в, ...</td>\n",
       "      <td>[i-e-treb-sub, i-e-treb-sub, O, O, O, O, O, O,...</td>\n",
       "      <td>[8, 133, 5, 428, 2, 42, 4, 2, 78, 1, 132, 42, ...</td>\n",
       "      <td>[6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12334</th>\n",
       "      <td>[;, 6, ), иметь, животноводческий, стоянка, ,,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[8, 185, 5, 205, 612, 1379, 1, 680, 6, 529, 25...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12335 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      [субсидия, предоставляться, в, предел, бюджетн...   \n",
       "1      [основной, понятие, ,, использовать, в, настоя...   \n",
       "2      [доступ, к, функция, сервис, для, участник, от...   \n",
       "3      [;, участник, отбор, -, представить, в, уполно...   \n",
       "4      [отбор, получатель, субсидия, проводиться, упо...   \n",
       "...                                                  ...   \n",
       "12330  [к, категория, получатель, субсидия, в, рамка,...   \n",
       "12331  [;, 2, ), получатель, субсидия, -, юридический...   \n",
       "12332  [;, (, в, ред, ., постановление, правительство...   \n",
       "12333  [;, 5, ), представить, в, министерство, (, в, ...   \n",
       "12334  [;, 6, ), иметь, животноводческий, стоянка, ,,...   \n",
       "\n",
       "                                                     tag  \\\n",
       "0      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "...                                                  ...   \n",
       "12330  [O, O, O, O, i-e-org-ul, O, O, O, O, i-e-org-u...   \n",
       "12331  [i-e-org-ul, i-e-org-ul, i-e-org-ul, i-e-treb-...   \n",
       "12332  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "12333  [i-e-treb-sub, i-e-treb-sub, O, O, O, O, O, O,...   \n",
       "12334  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                                text_ind  \\\n",
       "0      [10, 123, 2, 481, 83, 574, 3, 366, 83, 138, 1,...   \n",
       "1      [854, 549, 1, 384, 2, 34, 13, 53, 170, 4, 35, ...   \n",
       "2      [1653, 50, 400, 2198, 37, 27, 11, 339, 1279, 1...   \n",
       "3      [8, 27, 11, 7, 428, 2, 326, 100, 170, 4, 35, 5...   \n",
       "4      [11, 36, 10, 661, 326, 100, 562, 334, 170, 4, ...   \n",
       "...                                                  ...   \n",
       "12330  [50, 243, 36, 10, 2, 236, 34, 13, 503, 22, 16,...   \n",
       "12331  [8, 45, 5, 36, 10, 7, 22, 16, 1, 12, 199, 2, 1...   \n",
       "12332  [8, 4, 2, 141, 9, 62, 72, 393, 71, 32, 439, 9,...   \n",
       "12333  [8, 133, 5, 428, 2, 42, 4, 2, 78, 1, 132, 42, ...   \n",
       "12334  [8, 185, 5, 205, 612, 1379, 1, 680, 6, 529, 25...   \n",
       "\n",
       "                                                 tag_ind  \n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                  ...  \n",
       "12330  [1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 4, 4, 3, 3, ...  \n",
       "12331  [3, 3, 3, 9, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, ...  \n",
       "12332  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "12333  [6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "12334  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[12335 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceeb939c",
   "metadata": {
    "id": "ceeb939c"
   },
   "outputs": [],
   "source": [
    "with open('dict_words_100_.pkl', 'rb') as dict_words:\n",
    "    dict_words = pickle.load(dict_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be573f6a",
   "metadata": {
    "id": "be573f6a"
   },
   "outputs": [],
   "source": [
    "with open('dict_tegs_100_.pkl', 'rb') as dict_tegs:\n",
    "    dict_tegs = pickle.load(dict_tegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97afaba7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97afaba7",
    "outputId": "2e4eabe4-05d3-43db-ef3c-0d5b7999376d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_tegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9481f71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9481f71",
    "outputId": "45a23af8-f719-49a6-d139-8f2ba4b1f3f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6052"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_token = len(dict_words)\n",
    "n_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c5fd3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22c5fd3c",
    "outputId": "de0a5f11-2b21-4b9a-aea3-a3a7ed29af6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tag = len(dict_tegs)\n",
    "n_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3a09963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1725"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max([len(s) for s in  data['text_ind'].tolist()])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "179a2377",
   "metadata": {
    "id": "179a2377"
   },
   "outputs": [],
   "source": [
    "def get_pad_train_test_val(data):\n",
    "\n",
    "    #Pad tokens   \n",
    "    tokens = data['text_ind'].tolist()\n",
    "#     maxlen = max([len(s) for s in  data['text_ind'].tolist()])\n",
    "    maxlen =100\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
    "\n",
    "    #Pad Tags\n",
    "    tags = data['tag_ind'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= dict_tegs[\"o\"])\n",
    "    n_tags = len(dict_tegs)+1\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    #Split train, test and validation set\n",
    "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
    "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntrain_tags length:', len(train_tags),\n",
    "        '\\ntest_tokens length:', len(test_tokens),\n",
    "        '\\ntest_tags:', len(test_tags),\n",
    "        '\\nval_tokens:', len(val_tokens),\n",
    "        '\\nval_tags:', len(val_tags),\n",
    "    )\n",
    "    \n",
    "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "z3nrHvJQamcW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3nrHvJQamcW",
    "outputId": "60f956f4-c483-48df-ebf1-322626310029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408980\n",
      "682371\n",
      "0.5993513792350496\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "all=0\n",
    "for i in range(len(data[\"tag\"])):\n",
    "    count=0\n",
    "    for num in data[\"tag\"][i]:\n",
    "        all +=1\n",
    "        if num == \"O\":\n",
    "              count+=1\n",
    "\n",
    "    sum = sum + count\n",
    "print(sum)\n",
    "print(all)\n",
    "print(sum/all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee032d99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee032d99",
    "outputId": "cb7c5ca9-2ea6-4040-ca61-9d86d0f1cc31"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_pad_train_test_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m, in \u001b[0;36mget_pad_train_test_val\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#Split train, test and validation set\u001b[39;00m\n\u001b[0;32m     16\u001b[0m tokens_, test_tokens, tags_, test_tags \u001b[38;5;241m=\u001b[39m train_test_split(pad_tokens, pad_tags, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2020\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m train_tokens, val_tokens, train_tags, val_tags \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens_\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtags_\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_tokens length:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_tokens),\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtrain_tags length:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_tags),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mval_tags:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_tags),\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2583\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2579\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2581\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2583\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2586\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2160\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2127\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   2128\u001b[0m \n\u001b[0;32m   2129\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[0;32m   2159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2160\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m     )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    921\u001b[0m     _assert_all_finite(\n\u001b[0;32m    922\u001b[0m         array,\n\u001b[0;32m    923\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc7a38",
   "metadata": {
    "id": "39cc7a38"
   },
   "outputs": [],
   "source": [
    "# фиксируем состояния для воспроизводимости экспериментов\n",
    "from numpy.random import seed\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "565b8eac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "565b8eac",
    "outputId": "c07b8ced-5884-4396-ed35-aea2c75362b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  6053 \n",
      "output_dim:  8 \n",
      "input_length:  100 \n",
      "n_tags:  58\n"
     ]
    }
   ],
   "source": [
    "input_dim = n_token+1\n",
    "output_dim = 8\n",
    "# input_length = max([len(s) for s in  data['text_ind'].tolist()])\n",
    "input_length = 100\n",
    "n_tags = len(dict_tegs)+1\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142a6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4f323a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Activation, Conv1D,Conv2D\n",
    "import keras as k\n",
    "\n",
    "inp = Input(shape=(input_length,))\n",
    "\n",
    "# Embedding Layer\n",
    "x = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length)(inp)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# BI-LSTM Layer\n",
    "x_lstm = Bidirectional(LSTM(units=output_dim*2, \n",
    "                           return_sequences=True, \n",
    "                           dropout=0.2, \n",
    "                           recurrent_dropout=0.2, \n",
    "                           kernel_initializer=k.initializers.he_normal()))(x)\n",
    "\n",
    "x_lstm = Bidirectional(LSTM(units=output_dim, \n",
    "                           return_sequences=True, \n",
    "                           dropout=0.2, \n",
    "                           recurrent_dropout=0.2, \n",
    "                           kernel_initializer=k.initializers.he_normal()))(x_lstm)\n",
    "\n",
    "# x_conv3 = Conv1D(filters =128, kernel_size=3, padding='same', kernel_initializer='he_uniform')(x_lstm)\n",
    "# # avg_pool1_lstm = GlobalAveragePooling1D()(x_conv3)\n",
    "# # max_pool1_lstm = GlobalMaxPooling1D()(x_conv3)\n",
    "\n",
    "\n",
    "# x_conv4 = Conv1D(filters =128, kernel_size=2, padding='same', kernel_initializer='he_uniform')(x_lstm)\n",
    "# avg_pool2_lstm = GlobalAveragePooling1D()(x_conv4)\n",
    "# max_pool2_lstm = GlobalMaxPooling1D()(x_conv4)\n",
    "\n",
    "lstm1 = LSTM(64, return_sequences=True)(x_lstm)\n",
    "\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(lstm1)\n",
    "\n",
    "\n",
    "# TimeDistributed Layer\n",
    "x = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)  \n",
    "\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d914cdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 8)            48424     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 8)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100, 32)          3200      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 100, 16)          2624      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100, 64)           20736     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100, 64)           0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 100, 58)          3770      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,754\n",
      "Trainable params: 78,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\nadam.py:89: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "BATCH_SIZE=32\n",
    "#Optimiser \n",
    "nadam = tf.keras.optimizers.legacy.Nadam(lr=0.0003, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['categorical_accuracy'])\n",
    "\n",
    "model.build((BATCH_SIZE, input_length,))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3d4baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "261/261 [==============================] - 44s 170ms/step - loss: 0.7206 - categorical_accuracy: 0.8332 - val_loss: 0.7120 - val_categorical_accuracy: 0.8371\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 50s 191ms/step - loss: 0.7138 - categorical_accuracy: 0.8335 - val_loss: 0.7081 - val_categorical_accuracy: 0.8371\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 52s 199ms/step - loss: 0.7115 - categorical_accuracy: 0.8341 - val_loss: 0.7087 - val_categorical_accuracy: 0.8359\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 55s 210ms/step - loss: 0.7060 - categorical_accuracy: 0.8337 - val_loss: 0.7000 - val_categorical_accuracy: 0.8362\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 52s 200ms/step - loss: 0.7016 - categorical_accuracy: 0.8347 - val_loss: 0.7000 - val_categorical_accuracy: 0.8368\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 52s 200ms/step - loss: 0.6966 - categorical_accuracy: 0.8354 - val_loss: 0.6935 - val_categorical_accuracy: 0.8374\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 52s 199ms/step - loss: 0.6944 - categorical_accuracy: 0.8357 - val_loss: 0.6930 - val_categorical_accuracy: 0.8374\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 51s 196ms/step - loss: 0.6896 - categorical_accuracy: 0.8354 - val_loss: 0.6879 - val_categorical_accuracy: 0.8374\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 52s 198ms/step - loss: 0.6863 - categorical_accuracy: 0.8355 - val_loss: 0.6890 - val_categorical_accuracy: 0.8383\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 52s 197ms/step - loss: 0.6819 - categorical_accuracy: 0.8370 - val_loss: 0.6889 - val_categorical_accuracy: 0.8385\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 51s 194ms/step - loss: 0.6756 - categorical_accuracy: 0.8377 - val_loss: 0.6896 - val_categorical_accuracy: 0.8388\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 51s 197ms/step - loss: 0.6743 - categorical_accuracy: 0.8374 - val_loss: 0.6870 - val_categorical_accuracy: 0.8380\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 50s 193ms/step - loss: 0.6680 - categorical_accuracy: 0.8379 - val_loss: 0.6776 - val_categorical_accuracy: 0.8412\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 53s 201ms/step - loss: 0.6676 - categorical_accuracy: 0.8385 - val_loss: 0.6797 - val_categorical_accuracy: 0.8400\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 52s 198ms/step - loss: 0.6616 - categorical_accuracy: 0.8395 - val_loss: 0.6787 - val_categorical_accuracy: 0.8411\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 55s 210ms/step - loss: 0.6636 - categorical_accuracy: 0.8391 - val_loss: 0.6758 - val_categorical_accuracy: 0.8423\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 51s 196ms/step - loss: 0.6570 - categorical_accuracy: 0.8396 - val_loss: 0.6737 - val_categorical_accuracy: 0.8415\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 53s 202ms/step - loss: 0.6559 - categorical_accuracy: 0.8394 - val_loss: 0.6767 - val_categorical_accuracy: 0.8405\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 51s 197ms/step - loss: 0.6526 - categorical_accuracy: 0.8400 - val_loss: 0.6674 - val_categorical_accuracy: 0.8420\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 51s 194ms/step - loss: 0.6469 - categorical_accuracy: 0.8410 - val_loss: 0.6658 - val_categorical_accuracy: 0.8414\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 52s 200ms/step - loss: 0.6480 - categorical_accuracy: 0.8414 - val_loss: 0.6651 - val_categorical_accuracy: 0.8429\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 54s 208ms/step - loss: 0.6438 - categorical_accuracy: 0.8413 - val_loss: 0.6638 - val_categorical_accuracy: 0.8419\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 53s 203ms/step - loss: 0.6384 - categorical_accuracy: 0.8430 - val_loss: 0.6629 - val_categorical_accuracy: 0.8428\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 52s 199ms/step - loss: 0.6417 - categorical_accuracy: 0.8416 - val_loss: 0.6683 - val_categorical_accuracy: 0.8412\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 53s 201ms/step - loss: 0.6344 - categorical_accuracy: 0.8438 - val_loss: 0.6650 - val_categorical_accuracy: 0.8426\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 53s 203ms/step - loss: 0.6330 - categorical_accuracy: 0.8421 - val_loss: 0.6586 - val_categorical_accuracy: 0.8428\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 55s 211ms/step - loss: 0.6282 - categorical_accuracy: 0.8438 - val_loss: 0.6599 - val_categorical_accuracy: 0.8423\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 53s 205ms/step - loss: 0.6266 - categorical_accuracy: 0.8448 - val_loss: 0.6601 - val_categorical_accuracy: 0.8431\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 56s 216ms/step - loss: 0.6266 - categorical_accuracy: 0.8437 - val_loss: 0.6593 - val_categorical_accuracy: 0.8429\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 57s 220ms/step - loss: 0.6229 - categorical_accuracy: 0.8455 - val_loss: 0.6592 - val_categorical_accuracy: 0.8417\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 59s 225ms/step - loss: 0.6279 - categorical_accuracy: 0.8431 - val_loss: 0.6589 - val_categorical_accuracy: 0.8426\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 56s 213ms/step - loss: 0.6186 - categorical_accuracy: 0.8453 - val_loss: 0.6554 - val_categorical_accuracy: 0.8427\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 55s 209ms/step - loss: 0.6159 - categorical_accuracy: 0.8464 - val_loss: 0.6549 - val_categorical_accuracy: 0.8415\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 55s 213ms/step - loss: 0.6101 - categorical_accuracy: 0.8470 - val_loss: 0.6546 - val_categorical_accuracy: 0.8420\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 54s 205ms/step - loss: 0.6125 - categorical_accuracy: 0.8460 - val_loss: 0.6499 - val_categorical_accuracy: 0.8452\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 53s 203ms/step - loss: 0.6092 - categorical_accuracy: 0.8462 - val_loss: 0.6504 - val_categorical_accuracy: 0.8439\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 57s 219ms/step - loss: 0.6057 - categorical_accuracy: 0.8471 - val_loss: 0.6564 - val_categorical_accuracy: 0.8431\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 65s 250ms/step - loss: 0.6078 - categorical_accuracy: 0.8466 - val_loss: 0.6576 - val_categorical_accuracy: 0.8454\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 57s 220ms/step - loss: 0.6029 - categorical_accuracy: 0.8472 - val_loss: 0.6540 - val_categorical_accuracy: 0.8447\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 58s 221ms/step - loss: 0.6016 - categorical_accuracy: 0.8476 - val_loss: 0.6476 - val_categorical_accuracy: 0.8450\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 58s 221ms/step - loss: 0.6016 - categorical_accuracy: 0.8469 - val_loss: 0.6485 - val_categorical_accuracy: 0.8436\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 58s 224ms/step - loss: 0.5982 - categorical_accuracy: 0.8474 - val_loss: 0.6685 - val_categorical_accuracy: 0.8340\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 60s 230ms/step - loss: 0.5994 - categorical_accuracy: 0.8463 - val_loss: 0.6492 - val_categorical_accuracy: 0.8434\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 57s 219ms/step - loss: 0.5951 - categorical_accuracy: 0.8479 - val_loss: 0.6502 - val_categorical_accuracy: 0.8420\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 55s 213ms/step - loss: 0.5942 - categorical_accuracy: 0.8480 - val_loss: 0.6496 - val_categorical_accuracy: 0.8409\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 54s 207ms/step - loss: 0.5900 - categorical_accuracy: 0.8488 - val_loss: 0.6477 - val_categorical_accuracy: 0.8428\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 54s 208ms/step - loss: 0.5888 - categorical_accuracy: 0.8485 - val_loss: 0.6453 - val_categorical_accuracy: 0.8459\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 57s 217ms/step - loss: 0.5861 - categorical_accuracy: 0.8487 - val_loss: 0.6435 - val_categorical_accuracy: 0.8447\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 66s 254ms/step - loss: 0.5854 - categorical_accuracy: 0.8496 - val_loss: 0.6459 - val_categorical_accuracy: 0.8453\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 55s 212ms/step - loss: 0.5844 - categorical_accuracy: 0.8486 - val_loss: 0.6401 - val_categorical_accuracy: 0.8426\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = model.fit(train_tokens, np.array(train_tags), validation_data=(val_tokens, np.array(val_tags)), epochs=epochs, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af01ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        #self.init = initializations.get('glorot_uniform')\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
    "\n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "    #print weigthted_input.shape\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "\n",
    "model.add(Conv1D(250, 5, padding='same', activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "# model.add(GRU(64, return_sequences=True))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_tags, activation = \"softmax\"))\n",
    "\n",
    "nadam = tf.keras.optimizers.legacy.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['categorical_accuracy'])\n",
    "history = model.fit(train_tokens, np.array(train_tags), batch_size=256, epochs=10, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e164371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten, Masking\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd6b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f67534",
   "metadata": {
    "id": "d1f67534"
   },
   "outputs": [],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "# import keras as k\n",
    "# # from keras_contrib.layers import CRF\n",
    "\n",
    "# input = Input(shape=(input_length,))\n",
    "\n",
    "# # Embedding Layer\n",
    "# model = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length)(input)\n",
    "\n",
    "# # BI-LSTM Layer\n",
    "# model = Bidirectional(LSTM(units=output_dim, \n",
    "#                            return_sequences=True, \n",
    "#                            dropout=0.2, \n",
    "#                            recurrent_dropout=0.2, \n",
    "#                            kernel_initializer=k.initializers.he_normal()))(model)\n",
    "\n",
    "# model = LSTM(units=output_dim * 2, \n",
    "#              return_sequences=True, \n",
    "#              dropout=0.2, \n",
    "#              recurrent_dropout=0.2, \n",
    "#              kernel_initializer=k.initializers.he_normal())(model)\n",
    "\n",
    "# # TimeDistributed Layer\n",
    "# model = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  \n",
    "\n",
    "# # # CRF Layer\n",
    "# # crf = CRF(n_tags)\n",
    "\n",
    "# # out = crf(model)  # output\n",
    "\n",
    "\n",
    "# model = Model(input, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f533539",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_tokens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00075ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_tokens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_tags).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b3973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = tf.reshape(train_tokens , (4481,1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32846a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "# import keras as k\n",
    "# from keras_contrib.layers import CRF\n",
    "\n",
    "inputs = Input(shape=(input_length,), dtype=\"int32\")\n",
    "\n",
    "# Embedding Layer\n",
    "x_embed = Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=False, input_length=input_length)(inputs)\n",
    "\n",
    "\n",
    "# BI-LSTM Layer\n",
    "x_lstm_1 = Bidirectional(LSTM(units=output_dim, \n",
    "                           return_sequences=True, \n",
    "                           dropout=0.2, \n",
    "                           recurrent_dropout=0.2, \n",
    "                           kernel_initializer=k.initializers.he_normal()))(x_embed)\n",
    "\n",
    "outputs = Bidirectional(LSTM(units=output_dim, \n",
    "                           return_sequences=True, \n",
    "                           dropout=0.2, \n",
    "                           recurrent_dropout=0.2, \n",
    "                           kernel_initializer=k.initializers.he_normal()))(x_lstm_1)\n",
    "\n",
    "# outputs = LSTM(units=output_dim * 2, \n",
    "#              return_sequences=True, \n",
    "#              dropout=0.2, \n",
    "#              recurrent_dropout=0.2, \n",
    "#              kernel_initializer=k.initializers.he_normal())(x_lstm_1)\n",
    "\n",
    "\n",
    "# TimeDistributed Layer \n",
    "\n",
    "# # TimeDistributed Layer\n",
    "outputs = TimeDistributed(Dense(256, activation=\"relu\"))(outputs)  \n",
    "outputs = TimeDistributed(Dropout(0.4))(outputs)\n",
    "\n",
    "base_model = Model(inputs=inputs, outputs=outputs, name=\"bi_lstm\")\n",
    "\n",
    "model = CRFModelWrapper(base_model, units=n_tags)\n",
    "\n",
    "\n",
    "# model = Model(inputs, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ddd1a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4ddd1a1",
    "outputId": "21783871-6f7c-43cb-ddf5-ef253077944e"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Optimiser \n",
    "nadam = tf.keras.optimizers.legacy.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['categorical_accuracy'])\n",
    "\n",
    "model.build((BATCH_SIZE, input_length,))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c58514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeea6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_alarm1(y_true, y_pred): \n",
    "    k = 2\n",
    "    new_y_pred = tf.zeros_like(y_pred)\n",
    "    _ , indices = tf.math.top_k(y_pred, k = k)\n",
    "    batch_indices = tf.repeat(tf.range(tf.shape(y_pred)[0]), repeats=k)\n",
    "    indices = tf.stack([batch_indices, tf.reshape(indices,[-1])], axis=1)\n",
    "    new_y_pred = tf.tensor_scatter_nd_update(new_y_pred, indices, tf.ones(tf.reduce_prod(tf.shape(indices)[0])))\n",
    "    print(new_y_pred)\n",
    "\n",
    "    return tf.math.confusion_matrix(tf.reshape(y_true,[-1]), tf.reshape(new_y_pred,[-1]))\n",
    "\n",
    "print(false_alarm1(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445d7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ffb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit(train_tokens, np.array(train_tags), validation_data=(val_tokens, np.array(val_tags)), epochs=epochs, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386245f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b386245f",
    "outputId": "4e6e9b95-9e35-47e1-f88d-1c1cebdfc9d0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# history = model.fit(train_tokens, np.array(train_tags), batch_size=256, epochs=80, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2da46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DLDoLC9WTjQn",
   "metadata": {
    "id": "DLDoLC9WTjQn"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174fc15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "4174fc15",
    "outputId": "eb0015b1-84cd-44f6-f9bf-1343a1e2e2aa",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the graph \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    accuracy = history.history['categorical_accuracy']\n",
    "    val_accuracy = history.history['val_categorical_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(accuracy) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
    "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af20bde",
   "metadata": {
    "id": "3af20bde"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb513a",
   "metadata": {
    "id": "c7bb513a"
   },
   "outputs": [],
   "source": [
    "with open('test_labels_all.data', 'rb') as filehandle:  \n",
    "    test_labels = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c36dc",
   "metadata": {
    "id": "041c36dc"
   },
   "outputs": [],
   "source": [
    "with open('pred_labels_all.data', 'rb') as filehandle:  \n",
    "    pred_labels = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b35ee4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b35ee4b",
    "outputId": "55df4c47-9524-4d20-ebad-70a8014e34ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "key_list = list(dict_tegs.keys())\n",
    "val_list = list(dict_tegs.values())\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "            out_i = []\n",
    "            for p in pred_i:\n",
    "                p_i = np.argmax(p)\n",
    "                position = val_list.index(p_i)\n",
    "                out_i.append(key_list[position])\n",
    "            out.append(out_i)\n",
    "            \n",
    "    return out\n",
    "test_pred = model.predict(test_tokens, verbose=1)   \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ced2d5",
   "metadata": {
    "id": "e1ced2d5"
   },
   "outputs": [],
   "source": [
    "with open('test_labels_all.data', 'wb') as filehandle:\n",
    "    pickle.dump(test_labels, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a5f59f",
   "metadata": {
    "id": "f8a5f59f"
   },
   "outputs": [],
   "source": [
    "with open('pred_labels_all.data', 'wb') as filehandle:\n",
    "    pickle.dump(pred_labels, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36c2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_tegs_full.pkl', 'rb') as dict_tegs:\n",
    "    dict_tegs = pickle.load(dict_tegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data_entities_full.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b16a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_=[]\n",
    "for i in dict_tegs:\n",
    "    for j in data[\"tag\"]:\n",
    "        for k in j:\n",
    "            if i == k:\n",
    "                count+=1\n",
    "    dict_.append({i: count})\n",
    "    count=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f99f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_new=[]\n",
    "list_tegs=[]\n",
    "for i in dict_:\n",
    "    for key, value in i.items():\n",
    "\n",
    "        if value >=100 or key == 'o':\n",
    "            dict_new.append({key: value})\n",
    "            if key !='o':\n",
    "                list_tegs.append(key[2:])\n",
    "            else: list_tegs.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0792f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_tegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_tegs:\n",
    "    list_tegs[i] = i\n",
    "\n",
    "list_tegs[2][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('list_tegs100.txt', 'w') as filehandle:  \n",
    "    for listitem in list_tegs:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278daa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "places=[]\n",
    "# откроем файл и считаем его содержимое в список\n",
    "with open('listfile.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        # удалим заключительный символ перехода строки\n",
    "        currentPlace = line[:-1]\n",
    "\n",
    "        # добавим элемент в конец списка\n",
    "        places.append(currentPlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e18535",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac0d8175",
   "metadata": {
    "id": "ac0d8175"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hbv5dlWjaNoE",
   "metadata": {
    "id": "hbv5dlWjaNoE"
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    joined_true = []\n",
    "    joined_pred = []\n",
    "    for sent_true, sent_pred in zip(y_true, y_pred):\n",
    "        joined_true.extend(sent_true)\n",
    "        joined_pred.extend(sent_pred)\n",
    "        \n",
    "    print(classification_report(joined_true, joined_pred))\n",
    "#     print(support(joined_true, joined_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "C_PKQsgUaNq1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_PKQsgUaNq1",
    "outputId": "d17f36b0-fdc4-432a-b26a-e40c54604058"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "            i-e-block-treb       0.00      0.00      0.00       129\n",
      "                   i-e-obj       0.00      0.00      0.00       283\n",
      "                 i-e-okved       0.00      0.00      0.00        32\n",
      "            i-e-okved-main       0.00      0.00      0.00       109\n",
      "         i-e-org-coop-coop       0.00      0.00      0.00        56\n",
      "         i-e-org-coop-spok       0.00      0.00      0.00       204\n",
      "                i-e-org-ip       0.00      0.00      0.00       260\n",
      "               i-e-org-kfl       0.00      0.00      0.00        94\n",
      "               i-e-org-lph       0.00      0.00      0.00        99\n",
      "                i-e-org-sf       0.00      0.00      0.00        93\n",
      "                i-e-org-ul       0.43      0.06      0.11      2612\n",
      "             i-e-prod-cred       0.56      0.23      0.32       472\n",
      "              i-e-prod-liz       0.00      0.00      0.00       160\n",
      "            i-e-prod-strax       0.00      0.00      0.00        80\n",
      "                  i-e-reg-       0.00      0.00      0.00        65\n",
      "               i-e-reg-msp       0.00      0.00      0.00       322\n",
      "            i-e-treb-dogov       0.00      0.00      0.00       259\n",
      "             i-e-treb-dolg       0.00      0.00      0.00       328\n",
      "              i-e-treb-lic       0.00      0.00      0.00        61\n",
      "              i-e-treb-liq       0.00      0.00      0.00       436\n",
      "            i-e-treb-nalog       0.44      0.48      0.46      1995\n",
      "            i-e-treb-otbor       0.69      0.81      0.75      9695\n",
      "              i-e-treb-reg       0.00      0.00      0.00       333\n",
      "              i-e-treb-rez       0.00      0.00      0.00       623\n",
      "              i-e-treb-sub       0.00      0.00      0.00      1558\n",
      "                 i-e-v-eda       0.00      0.00      0.00       165\n",
      "             i-e-v-eda-eda       0.00      0.00      0.00        23\n",
      "                 i-e-v-gkh       0.00      0.00      0.00       172\n",
      "           i-e-v-gkh-othod       0.00      0.00      0.00        16\n",
      "           i-e-v-gkh-teplo       0.00      0.00      0.00       177\n",
      "                i-e-v-selh       0.12      0.05      0.07      1528\n",
      "           i-e-v-selh-anim       0.00      0.00      0.00       319\n",
      "      i-e-v-selh-anim-bird       0.00      0.00      0.00       159\n",
      "       i-e-v-selh-anim-krs       0.00      0.00      0.00        19\n",
      "  i-e-v-selh-anim-krs-maso       0.00      0.00      0.00        19\n",
      "  i-e-v-selh-anim-krs-milk       0.00      0.00      0.00       115\n",
      "i-e-v-selh-anim-krs-plemya       0.00      0.00      0.00       243\n",
      " i-e-v-selh-anim-krs-semya       0.00      0.00      0.00         9\n",
      "      i-e-v-selh-anim-ovca       0.00      0.00      0.00        12\n",
      "           i-e-v-selh-fish       0.00      0.00      0.00        32\n",
      "       i-e-v-selh-fish-eda       0.00      0.00      0.00        13\n",
      "           i-e-v-selh-rast       0.09      0.09      0.09       479\n",
      "    i-e-v-selh-rast-kartof       0.00      0.00      0.00        21\n",
      "       i-e-v-selh-rast-len       0.00      0.00      0.00         1\n",
      "i-e-v-selh-rast-ovosh-otkr       0.00      0.00      0.00        42\n",
      "i-e-v-selh-rast-ovosh-zakr       0.00      0.00      0.00        13\n",
      " i-e-v-selh-rast-vino-rast       0.00      0.00      0.00        35\n",
      "     i-e-v-selh-rast-zerno       0.00      0.00      0.00       173\n",
      "              i-e-v-transp       0.00      0.00      0.00       535\n",
      "          i-e-v-transp-air       0.00      0.00      0.00       119\n",
      "         i-e-v-transp-avto       0.00      0.00      0.00         8\n",
      "           i-e-v-transp-gd       0.00      0.00      0.00        22\n",
      "       i-e-v-transp-zaprav       0.00      0.00      0.00        88\n",
      "                 i-e-v-tur       0.00      0.00      0.00        71\n",
      "           i-e-v-tur-child       0.00      0.00      0.00         6\n",
      "                       i-o       0.00      0.00      0.00       142\n",
      "                         o       0.88      0.97      0.92     98266\n",
      "\n",
      "                  accuracy                           0.85    123400\n",
      "                 macro avg       0.06      0.05      0.05    123400\n",
      "              weighted avg       0.78      0.85      0.81    123400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_score(test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca837e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed60624",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_train = []\n",
    "# joined_pred = []\n",
    "\n",
    "for i in train_tags:\n",
    "    joined_train.extend(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(joined_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4468c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_true = []\n",
    "joined_pred = []\n",
    "for sent_true, sent_pred in zip(test_labels, pred_labels):\n",
    "    joined_true.extend(sent_true)\n",
    "    joined_pred.extend(sent_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(joined_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de41266",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(joined_true))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
