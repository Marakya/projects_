{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff5c1c6",
   "metadata": {},
   "source": [
    "# Парсим "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1010fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be342394",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_with_entities = []\n",
    "for file in os.listdir('Разметка_все/'):\n",
    "    if '.json' in file:\n",
    "        with open(f'Разметка_все/{file}', 'r',  encoding=\"utf8\") as json_data:\n",
    "            json_text = json.load(json_data)\n",
    "            \n",
    "            for text_object in json_text:\n",
    "                try: \n",
    "                    main_text = text_object['result'][list(text_object['result'].keys())[0]]['result']['marks'][0]['text']\n",
    "                    ents = []\n",
    "                    for entity_object in text_object['result'][list(text_object['result'].keys())[0]]['result']['marks'][1:]:\n",
    "\n",
    "                        text = entity_object['text']\n",
    "                        type_ = entity_object['entityId']\n",
    "                        start = entity_object['position']['start']\n",
    "                        end = entity_object['position']['end']\n",
    "\n",
    "                        ents.append((text, type_, start, end))\n",
    "                except: pass\n",
    "                    \n",
    "                texts_with_entities.append((main_text, ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0365f531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 35232)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_with_entities), sum([len(sample[1]) for sample in texts_with_entities])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9cd0e6",
   "metadata": {},
   "source": [
    "# BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e101dc",
   "metadata": {},
   "source": [
    "# e-obj и другие NE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3441175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37756b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_sentences = []\n",
    "for text, _ in texts_with_entities:\n",
    "    \n",
    "    sentences_bounds = {}\n",
    "    start = 0\n",
    "    \n",
    "    for sentence in sent_tokenize(text, language='russian'):\n",
    "        \n",
    "        end = start + len(sentence)\n",
    "        end += 1\n",
    "        \n",
    "        sentences_bounds[(start, end)] = sentence\n",
    "        start = end\n",
    "        \n",
    "    text_to_sentences.append(sentences_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4d7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc4fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [elem[0] for elem in texts_with_entities]\n",
    "entities = [elem[1] for elem in texts_with_entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a8857a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82361"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(text_to_sentences[i].keys()) for i in range(len(text_to_sentences))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f627e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_with_ents = {}\n",
    "c = 0\n",
    "for i in range(len(texts)):\n",
    "    current_doc_ents = entities[i]\n",
    "    for sentence_borders in text_to_sentences[i].keys():\n",
    "        for ent in current_doc_ents:\n",
    "#             print(ent[2])\n",
    "            if ent[2] > sentence_borders[0] and ent[3] < sentence_borders[1]:\n",
    "                if (i, sentence_borders[0], sentence_borders[1]) in sentences_with_ents.keys():\n",
    "                    sentences_with_ents[i, sentence_borders[0], sentence_borders[1]].append((ent[0], ent[1], ent[2], ent[3]))\n",
    "                else:\n",
    "                    sentences_with_ents[i, sentence_borders[0], sentence_borders[1]] = [(ent[0], ent[1], ent[2], ent[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8071fa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a7c03b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5370"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_with_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b819f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_tokens(sentence, current_start):\n",
    "    tokens = {}\n",
    "    start_in_sequence = 0\n",
    "    for token in wordpunct_tokenize(sentence):\n",
    "        token_start = sentence[start_in_sequence:].find(token) + start_in_sequence + current_start\n",
    "        token_end = token_start + len(token) - 1\n",
    "        start_in_sequence = token_end - current_start\n",
    "        tokens[token_start, token_end] = token  \n",
    "    return tokens\n",
    "\n",
    "def find_token(tokens, pos, mode):\n",
    "    chosen_token = ''\n",
    "    for token_start, token_end in tokens.keys():\n",
    "        if token_start < pos < token_end:\n",
    "            return tokens[token_start, token_end]\n",
    "        elif token_end >= pos + 1 >= token_start and mode == 'start':\n",
    "            return tokens[token_start, token_end]\n",
    "        elif token_start <= pos - 1 <= token_end and mode == 'end':\n",
    "            return tokens[token_start, token_end]\n",
    "    \n",
    "    return chosen_token\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92fa0b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Мама',\n",
       " {(100, 103): 'Мама',\n",
       "  (105, 108): 'мыла',\n",
       "  (109, 109): ',',\n",
       "  (111, 114): 'раму',\n",
       "  (115, 115): '!'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Мама мыла, раму!'\n",
    "tokens = sentence_to_tokens(sentence, 100)\n",
    "find_token(tokens, 104, mode='end'), tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5f31459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5370"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_samples = []\n",
    "b = 0\n",
    "e = 0\n",
    "for text_idx, sent_start, sent_end in sentences_with_ents.keys():\n",
    "    \n",
    "    sentence = text_to_sentences[text_idx][(sent_start, sent_end)]\n",
    "    tokens = sentence_to_tokens(sentence, sent_start)\n",
    "    tokens_list = list(tokens.values())\n",
    "    markup = ['O' for token in tokens_list]\n",
    "    \n",
    "    for entity in sentences_with_ents[(text_idx, sent_start, sent_end)]:\n",
    "        \n",
    "        start_token = find_token(tokens, entity[2], mode='start')\n",
    "        end_token = find_token(tokens, entity[3], mode='end')\n",
    "        \n",
    "        if start_token == end_token and start_token != '':\n",
    "            markup[tokens_list.index(start_token)] = f'i-{entity[1]}'\n",
    "        elif start_token != '' and end_token != '':\n",
    "            markup[tokens_list.index(start_token)] = f'i-{entity[1]}'\n",
    "            markup[tokens_list.index(end_token)] = f'i-{entity[1]}'\n",
    "            for i in range(tokens_list.index(start_token) + 1, tokens_list.index(end_token)):\n",
    "                markup[i] = f'i-{entity[1]}'\n",
    "            \n",
    "        \n",
    "    bio_samples.append((sentence, markup))\n",
    "len(bio_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680dfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordpunct_tokenize(bio_samples[5][0]), bio_samples[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ce4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio_samples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2215800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe66cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bio_all.pickle', 'wb') as file:\n",
    "    pickle.dump(bio_samples, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c767c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bio_all.pickle', 'rb') as file:\n",
    "    bio = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c653caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for i in bio:\n",
    "    text.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ae65fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = []\n",
    "\n",
    "for i in bio:\n",
    "    tag.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b955ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tuples = list(zip(text, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6a8e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.DataFrame(list_tuples, columns=['text', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "850f91e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Субсидии предоставляются в пределах бюджетных ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Основные понятия, используемые в настоящем Пор...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Доступ к функциям сервиса для участников отбор...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Отбор получателей субсидии проводится уполномо...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Объявление о проведении отбора размещается на ...</td>\n",
       "      <td>[O, O, O, i-e-treb-otbor, i-e-treb-otbor, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>На дату подачи заявления претенденты должны со...</td>\n",
       "      <td>[O, O, O, O, i-e-treb-rez, O, O, O, O, O, i-e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>Настоящий Порядок определяет категории юридиче...</td>\n",
       "      <td>[O, O, O, O, i-e-org-ul, i-e-org-ul, i-e-org-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>В условиях настоящего Порядка используются сле...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>Субсидированию подлежит часть фактически подтв...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>К категории получателей субсидии в рамках наст...</td>\n",
       "      <td>[O, O, O, O, i-e-org-ul, O, O, O, O, i-e-org-u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     Субсидии предоставляются в пределах бюджетных ...   \n",
       "1     Основные понятия, используемые в настоящем Пор...   \n",
       "2     Доступ к функциям сервиса для участников отбор...   \n",
       "3     Отбор получателей субсидии проводится уполномо...   \n",
       "4     Объявление о проведении отбора размещается на ...   \n",
       "...                                                 ...   \n",
       "5365  На дату подачи заявления претенденты должны со...   \n",
       "5366  Настоящий Порядок определяет категории юридиче...   \n",
       "5367  В условиях настоящего Порядка используются сле...   \n",
       "5368  Субсидированию подлежит часть фактически подтв...   \n",
       "5369  К категории получателей субсидии в рамках наст...   \n",
       "\n",
       "                                                    tag  \n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4     [O, O, O, i-e-treb-otbor, i-e-treb-otbor, O, O...  \n",
       "...                                                 ...  \n",
       "5365  [O, O, O, O, i-e-treb-rez, O, O, O, O, O, i-e-...  \n",
       "5366  [O, O, O, O, i-e-org-ul, i-e-org-ul, i-e-org-u...  \n",
       "5367  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5368  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5369  [O, O, O, O, i-e-org-ul, O, O, O, O, i-e-org-u...  \n",
       "\n",
       "[5370 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "895b99f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2-dicts in c:\\users\\pc\\anaconda3\\lib\\site-packages (2.4.393442.3710985)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Error parsing requirements for yarl: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\yarl-1.6.3.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for xlsxwriter: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\XlsxWriter-3.0.3.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for xlrd: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\xlrd-2.0.1.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for typed-ast: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\typed_ast-1.4.3.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for tinycss: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\tinycss-0.4.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for rsa: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\rsa-4.7.2.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for olefile: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\olefile-0.46.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for nose: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\nose-1.3.7.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for multidict: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\multidict-5.1.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for jdcal: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\jdcal-1.4.1.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for googleapis-common-protos: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\googleapis_common_protos-1.53.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for google-resumable-media: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\google_resumable_media-1.3.1.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for google-crc32c: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\google_crc32c-1.1.2.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for frozenlist: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\frozenlist-1.2.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for cython: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\Cython-0.29.28.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for conda-pack: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\conda_pack-0.6.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for cachetools: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\cachetools-4.2.2.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for black: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\black-19.10b0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for bitarray: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\bitarray-2.4.1.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for aiosignal: [Errno 2] No such file or directory: 'c:\\\\users\\\\pc\\\\anaconda3\\\\lib\\\\site-packages\\\\aiosignal-1.2.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pymorphy2\n",
    "!pip install pymorphy2-dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3eb5c",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49462e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5aa6431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MORPH = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15197b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    wrds = []\n",
    "    for wrd in nltk.wordpunct_tokenize(data[\"text\"][i]):\n",
    "        wrd = MORPH.parse(wrd)[0].normal_form\n",
    "        wrds.append(wrd)\n",
    "\n",
    "    data.at[i, \"text\"] = wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65980ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[субсидия, предоставляться, в, предел, бюджетн...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[основной, понятие, ,, использовать, в, настоя...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[доступ, к, функция, сервис, для, участник, от...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[отбор, получатель, субсидия, проводиться, упо...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[объявление, о, проведение, отбор, размещаться...</td>\n",
       "      <td>[O, O, O, i-e-treb-otbor, i-e-treb-otbor, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>[на, дата, подача, заявление, претендент, долж...</td>\n",
       "      <td>[O, O, O, O, i-e-treb-rez, O, O, O, O, O, i-e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>[настоящий, порядок, определять, категория, юр...</td>\n",
       "      <td>[O, O, O, O, i-e-org-ul, i-e-org-ul, i-e-org-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>[в, условие, настоящий, порядок, использоватьс...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>[субсидирование, подлежать, часть, фактически,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>[к, категория, получатель, субсидия, в, рамка,...</td>\n",
       "      <td>[O, O, O, O, i-e-org-ul, O, O, O, O, i-e-org-u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     [субсидия, предоставляться, в, предел, бюджетн...   \n",
       "1     [основной, понятие, ,, использовать, в, настоя...   \n",
       "2     [доступ, к, функция, сервис, для, участник, от...   \n",
       "3     [отбор, получатель, субсидия, проводиться, упо...   \n",
       "4     [объявление, о, проведение, отбор, размещаться...   \n",
       "...                                                 ...   \n",
       "5365  [на, дата, подача, заявление, претендент, долж...   \n",
       "5366  [настоящий, порядок, определять, категория, юр...   \n",
       "5367  [в, условие, настоящий, порядок, использоватьс...   \n",
       "5368  [субсидирование, подлежать, часть, фактически,...   \n",
       "5369  [к, категория, получатель, субсидия, в, рамка,...   \n",
       "\n",
       "                                                    tag  \n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4     [O, O, O, i-e-treb-otbor, i-e-treb-otbor, O, O...  \n",
       "...                                                 ...  \n",
       "5365  [O, O, O, O, i-e-treb-rez, O, O, O, O, O, i-e-...  \n",
       "5366  [O, O, O, O, i-e-org-ul, i-e-org-ul, i-e-org-u...  \n",
       "5367  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5368  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5369  [O, O, O, O, i-e-org-ul, O, O, O, O, i-e-org-u...  \n",
       "\n",
       "[5370 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb241c83",
   "metadata": {},
   "source": [
    "### Данные в числовой вид"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3b6a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bafbd915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3295"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max([len(s) for s in data[\"text\"]])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a6fdd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer1 = Tokenizer(num_words=3295, filters=\"!»#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\")\n",
    "# Токенайзер обновляет словарь токенов в соответствии с частотой вхождения слов.\n",
    "tokenizer1.fit_on_texts(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9578703",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences1 = tokenizer1.texts_to_sequences(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d572d3fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m word_indexes \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer1\u001b[49m\u001b[38;5;241m.\u001b[39mword_index\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer1' is not defined"
     ]
    }
   ],
   "source": [
    "word_indexes = tokenizer1.word_index\n",
    "# word_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bfee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer2 = Tokenizer(num_words=3295, filters=\"!»#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\")\n",
    "# Токенайзер обновляет словарь токенов в соответствии с частотой вхождения слов.\n",
    "tokenizer2.fit_on_texts(data[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ec6e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences2 = tokenizer2.texts_to_sequences(data[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5063b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o': 1,\n",
       " 'i-e-treb-otbor': 2,\n",
       " 'i-e-org-ul': 3,\n",
       " 'i-e-v-selh': 4,\n",
       " 'i-e-treb-nalog': 5,\n",
       " 'i-e-treb-sub': 6,\n",
       " 'i-e-treb-rez': 7,\n",
       " 'i-e-v-selh-anim': 8,\n",
       " 'i-e-treb-liq': 9,\n",
       " 'i-e-prod-cred': 10,\n",
       " 'i-e-v-transp': 11,\n",
       " 'i-e-v-selh-rast': 12,\n",
       " 'i-e-reg-msp': 13,\n",
       " 'i-e-treb-dogov': 14,\n",
       " 'i-e-org-ip': 15,\n",
       " 'i-e-treb-dolg': 16,\n",
       " 'i-e-prod-liz': 17,\n",
       " 'i-e-obj': 18,\n",
       " 'i-e-org-coop-spok': 19,\n",
       " 'i-e-v-gkh': 20,\n",
       " 'i-e-v-selh-anim-krs-plemya': 21,\n",
       " 'i-e-org-kfl': 22,\n",
       " 'i-e-v-transp-zaprav': 23,\n",
       " 'i-e-treb-reg': 24,\n",
       " 'i-e-reg-': 25,\n",
       " 'i-e-org-sf': 26,\n",
       " 'i-e-v-selh-rast-zerno': 27,\n",
       " 'i-e-block-treb': 28,\n",
       " 'i-e-v-selh-anim-krs-milk': 29,\n",
       " 'i-e-v-transp-air': 30,\n",
       " 'i-e-v-tur': 31,\n",
       " 'i-e-prod-strax': 32,\n",
       " 'i-e-org-lph': 33,\n",
       " 'i-e-v-eda-eda': 34,\n",
       " 'i-e-okved': 35,\n",
       " 'i-e-v-selh-rast-kartof': 36,\n",
       " 'i-e-v-eda': 37,\n",
       " 'i-e-org-coop-coop': 38,\n",
       " 'i-e-v-selh-anim-ovca': 39,\n",
       " 'i-e-v-gkh-othod': 40,\n",
       " 'i-e-v-selh-anim-bird': 41,\n",
       " 'i-e-v-selh-fish': 42,\n",
       " 'i-e-okved-main': 43,\n",
       " 'i-e-v-selh-anim-krs': 44,\n",
       " 'i-e-v-transp-avto': 45,\n",
       " 'i-e-v-transp-gd': 46,\n",
       " 'i-e-v-selh-anim-krs-semya': 47,\n",
       " 'i-e-v-selh-rast-ovosh-otkr': 48,\n",
       " 'i-e-v-gkh-teplo': 49,\n",
       " 'i-e-treb-lic': 50,\n",
       " 'i-e-v-selh-fish-eda': 51,\n",
       " 'i-e-v-selh-anim-krs-maso': 52,\n",
       " 'i-e-v-selh-rast-vino-rast': 53,\n",
       " 'i-e-v-tur-child': 54,\n",
       " 'i-e-v-selh-rast-len': 55,\n",
       " 'i-e-v-selh-rast-ovosh-zakr': 56,\n",
       " 'i-e-v-selh-rast-grecha': 57,\n",
       " 'i-e-v-transp-vodn': 58,\n",
       " 'i-e-v-selh-rast-sachar-svecl': 59,\n",
       " 'i-e-reg-toser': 60,\n",
       " 'i-e-v-selh-rast-sad': 61,\n",
       " 'i-e-v-selh-rast-vino': 62,\n",
       " 'i-e-org-mfh': 63,\n",
       " 'i-e-org-comm': 64,\n",
       " 'i-e-v-selh-anim-ovca-milk': 65,\n",
       " 'i-e-v-selh-rast-yagod': 66,\n",
       " 'i-e-v-lizing': 67,\n",
       " 'i-text': 68,\n",
       " 'i-e-org-bu': 69,\n",
       " 'i-e-v-eda-hleb': 70,\n",
       " 'i-e-v-selh-rast-ovosh': 71,\n",
       " 'i-e-v-eda-fish': 72,\n",
       " 'i-e-v-selh-rast-ris': 73,\n",
       " 'i-e-v-selh-rast-tea': 74,\n",
       " 'i-e-v-transp-kanat': 75,\n",
       " 'i-e-org-coop-shk': 76,\n",
       " 'i-e-v-eda-soch-hleb': 77}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_indexes = tokenizer2.word_index\n",
    "tag_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "724f5005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6064"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_token = len(list(set(word_indexes)))\n",
    "n_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e327b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text_ind\"] = list(map(list, data[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40c533ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[\"text\"])):\n",
    "    data.at[i, \"text_ind\"] = sequences1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8c3459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tag_ind\"] = list(map(list, data[\"tag\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94257493",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[\"tag\"])):\n",
    "    data.at[i, \"tag_ind\"] = sequences2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2fe7494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>text_ind</th>\n",
       "      <th>tag_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[субсидия, предоставляться, в, предел, бюджетн...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[10, 124, 2, 482, 83, 576, 3, 367, 83, 139, 1,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[основной, понятие, ,, использовать, в, настоя...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[856, 551, 1, 385, 2, 34, 13, 53, 171, 4, 35, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[доступ, к, функция, сервис, для, участник, от...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[1656, 50, 401, 2201, 37, 27, 11, 340, 1281, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[отбор, получатель, субсидия, проводиться, упо...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[11, 36, 10, 663, 327, 100, 564, 335, 171, 4, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[объявление, о, проведение, отбор, размещаться...</td>\n",
       "      <td>[O, O, O, i-e-treb-otbor, i-e-treb-otbor, O, O...</td>\n",
       "      <td>[114, 17, 41, 11, 536, 7, 158, 222, 83, 304, 2...</td>\n",
       "      <td>[1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>[на, дата, подача, заявление, претендент, долж...</td>\n",
       "      <td>[O, O, O, O, i-e-treb-rez, O, O, O, O, O, i-e-...</td>\n",
       "      <td>[7, 57, 89, 143, 445, 40, 141, 82, 60, 53, 12,...</td>\n",
       "      <td>[1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 16, 16, 1, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>[настоящий, порядок, определять, категория, юр...</td>\n",
       "      <td>[O, O, O, O, i-e-org-ul, i-e-org-ul, i-e-org-u...</td>\n",
       "      <td>[34, 13, 252, 244, 22, 16, 4, 28, 79, 52, 4, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>[в, условие, настоящий, порядок, использоватьс...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[2, 77, 34, 13, 674, 82, 551, 53, 73, 25, 66, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>[субсидирование, подлежать, часть, фактически,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[1034, 774, 107, 673, 626, 73, 25, 66, 1, 456,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>[к, категория, получатель, субсидия, в, рамка,...</td>\n",
       "      <td>[O, O, O, O, i-e-org-ul, O, O, O, O, i-e-org-u...</td>\n",
       "      <td>[50, 244, 36, 10, 2, 237, 34, 13, 504, 22, 16,...</td>\n",
       "      <td>[1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 4, 4, 3, 3, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5370 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     [субсидия, предоставляться, в, предел, бюджетн...   \n",
       "1     [основной, понятие, ,, использовать, в, настоя...   \n",
       "2     [доступ, к, функция, сервис, для, участник, от...   \n",
       "3     [отбор, получатель, субсидия, проводиться, упо...   \n",
       "4     [объявление, о, проведение, отбор, размещаться...   \n",
       "...                                                 ...   \n",
       "5365  [на, дата, подача, заявление, претендент, долж...   \n",
       "5366  [настоящий, порядок, определять, категория, юр...   \n",
       "5367  [в, условие, настоящий, порядок, использоватьс...   \n",
       "5368  [субсидирование, подлежать, часть, фактически,...   \n",
       "5369  [к, категория, получатель, субсидия, в, рамка,...   \n",
       "\n",
       "                                                    tag  \\\n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4     [O, O, O, i-e-treb-otbor, i-e-treb-otbor, O, O...   \n",
       "...                                                 ...   \n",
       "5365  [O, O, O, O, i-e-treb-rez, O, O, O, O, O, i-e-...   \n",
       "5366  [O, O, O, O, i-e-org-ul, i-e-org-ul, i-e-org-u...   \n",
       "5367  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "5368  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "5369  [O, O, O, O, i-e-org-ul, O, O, O, O, i-e-org-u...   \n",
       "\n",
       "                                               text_ind  \\\n",
       "0     [10, 124, 2, 482, 83, 576, 3, 367, 83, 139, 1,...   \n",
       "1     [856, 551, 1, 385, 2, 34, 13, 53, 171, 4, 35, ...   \n",
       "2     [1656, 50, 401, 2201, 37, 27, 11, 340, 1281, 1...   \n",
       "3     [11, 36, 10, 663, 327, 100, 564, 335, 171, 4, ...   \n",
       "4     [114, 17, 41, 11, 536, 7, 158, 222, 83, 304, 2...   \n",
       "...                                                 ...   \n",
       "5365  [7, 57, 89, 143, 445, 40, 141, 82, 60, 53, 12,...   \n",
       "5366  [34, 13, 252, 244, 22, 16, 4, 28, 79, 52, 4, 1...   \n",
       "5367  [2, 77, 34, 13, 674, 82, 551, 53, 73, 25, 66, ...   \n",
       "5368  [1034, 774, 107, 673, 626, 73, 25, 66, 1, 456,...   \n",
       "5369  [50, 244, 36, 10, 2, 237, 34, 13, 504, 22, 16,...   \n",
       "\n",
       "                                                tag_ind  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4     [1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                 ...  \n",
       "5365  [1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 16, 16, 1, 1, 1...  \n",
       "5366  [1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "5367  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "5368  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "5369  [1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 4, 4, 3, 3, ...  \n",
       "\n",
       "[5370 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fa345",
   "metadata": {},
   "source": [
    "#### Сохраним датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9223f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('data_entities.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9d3820b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data_entities.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e30dcefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_tegs.pkl', 'wb') as f:\n",
    "    pickle.dump(tag_indexes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a449dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_words.pkl', 'wb') as f:\n",
    "    pickle.dump(word_indexes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d765e4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
